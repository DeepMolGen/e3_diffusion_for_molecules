{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of **Conditional Sampling** EDM: E(3) Equivariant Diffusion Model for Molecule Generation in 3D.\n",
    "[Github repo](https://github.com/ehoogeboom/e3_diffusion_for_molecules)\n",
    "\n",
    "- __Quantitative__: \n",
    "    - `main_quantitative`\n",
    "    - Different options for task: `edm, qm9_second_half, naive`\n",
    "    - Calls `qm9.property_prediction.main_qm9_prop.test` $\\to$ `train` but on `test` dataset\n",
    "- __Qualitative__: `main_qualitative`\n",
    "    - Calls `save_and_sample_conditional` $\\to$ `qm9.sampling.sample_sweep_conditional`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Arguments\n",
    "This arguments are not relevant because the arguments used to train the model are going to be loaded to sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, torch\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--exp_name', type=str, default='exploration_luisa')\n",
    "#parser.add_argument('--generators_path', type=str, default='outputs/exp_cond_alpha_pretrained') #original\n",
    "parser.add_argument('--generators_path', type=str, default='outputs/exp_35_conditional_nf192_9l_alpha')\n",
    "parser.add_argument('--classifiers_path', type=str, default='qm9/property_prediction/outputs/exp_class_alpha_pretrained')\n",
    "parser.add_argument('--property', type=str, default='mu',\n",
    "                    help=\"'alpha', 'homo', 'lumo', 'gap', 'mu', 'Cv'\")\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='enables CUDA training')\n",
    "parser.add_argument('--debug_break', type=eval, default=False,\n",
    "                    help='break point or not')\n",
    "parser.add_argument('--log_interval', type=int, default=5,\n",
    "                    help='break point or not')\n",
    "parser.add_argument('--batch_size', type=int, default=1,\n",
    "                    help='break point or not')\n",
    "parser.add_argument('--iterations', type=int, default=20,\n",
    "                    help='break point or not')\n",
    "parser.add_argument('--task', type=str, default='qualitative',\n",
    "                    help='naive, edm, qm9_second_half, qualitative')\n",
    "parser.add_argument('--n_sweeps', type=int, default=1,\n",
    "                    help='number of sweeps for the qualitative conditional experiment')\n",
    "args = parser.parse_args(args=[])\n",
    "device = torch.device(\"cpu\")\n",
    "args.device = device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Qualitative\n",
    "We use a pre-trained model that was saved to `outputs/exp_35_conditional_nf192_9l_alpha`. We are going to discover that such a model was trained to condition on `alpha` exclusively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_conditional_qm9 import get_args_gen, get_dataloader, get_generator\n",
    "\n",
    "# get the args used for training the generative model\n",
    "args_gen = get_args_gen(args.generators_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(exp_name='exp_35_conditional_nf192_9l_alpha', model='egnn_dynamics', probabilistic_model='diffusion', diffusion_steps=1000, diffusion_noise_schedule='polynomial_2', diffusion_noise_precision=1e-05, diffusion_loss_type='l2', n_epochs=3000, batch_size=64, lr=0.0001, brute_force=False, actnorm=True, break_train_epoch=False, dp=True, condition_time=True, clip_grad=True, trace='hutch', n_layers=9, inv_sublayers=1, nf=192, tanh=True, attention=True, norm_constant=1, sin_embedding=False, ode_regularization=0.001, dataset='qm9_second_half', datadir='qm9/temp', filter_n_atoms=None, dequantization='deterministic', n_report_steps=1, wandb_usr='vgsatorras', no_wandb=False, online=True, no_cuda=False, save_model=True, generate_epochs=1, num_workers=0, test_epochs=10, data_augmentation=False, conditioning=['alpha'], resume=None, start_epoch=0, ema_decay=0.999, augment_noise=0, n_stability_samples=500, normalize_factors=[1, 8, 1], remove_h=False, include_charges=False, visualize_every_batch=100000000.0, normalization_factor=1, cuda=True, context_node_nf=1, current_epoch=2741, aggregation_method='sum')\n",
      "['alpha']\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# exploration of arguments used to train the model\n",
    "print(args_gen)\n",
    "print(args_gen.conditioning) # this means that the model was trained to condition only alpha\n",
    "print(args_gen.context_node_nf) # only one because alpha is a global variable (1 scalar per molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of n_nodes: H[N] -2.4754221439361572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisaorozco/Documents/Projects/DeepMolGen/e3_diffusion_for_molecules/qm9/models.py:139: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  probs = Categorical(torch.tensor(probs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphas2 [9.99990000e-01 9.99988000e-01 9.99982000e-01 ... 2.59676966e-05\n",
      " 1.39959211e-05 1.00039959e-05]\n",
      "gamma [-11.51291546 -11.33059532 -10.92513058 ...  10.55863126  11.17673063\n",
      "  11.51251595]\n"
     ]
    }
   ],
   "source": [
    "from qm9.utils import compute_mean_mad \n",
    "dataloaders = get_dataloader(args_gen)\n",
    "property_norms = compute_mean_mad(dataloaders, args_gen.conditioning, args_gen.dataset)\n",
    "model, nodes_dist, prop_dist, dataset_info = get_generator(args.generators_path, dataloaders, \n",
    "                                                           args.device, args_gen, property_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exploration of the model\n",
    "model.T # timesteps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': {3: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(12.9900), tensor(12.9900)]},\n",
       "  4: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(9.4600), tensor(27.7000)]},\n",
       "  5: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(13.2100), tensor(32.6600)]},\n",
       "  6: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(21.5700), tensor(38.5200)]},\n",
       "  7: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(24.0400), tensor(43.8600)]},\n",
       "  8: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(23.9500), tensor(72.3900)]},\n",
       "  9: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(28.1300), tensor(88.8500)]},\n",
       "  10: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(34.5600), tensor(100.8600)]},\n",
       "  11: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(34.7500), tensor(92.3400)]},\n",
       "  12: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(41.5700), tensor(130.8600)]},\n",
       "  13: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(43.0700), tensor(112.7700)]},\n",
       "  14: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(45.7100), tensor(115.6600)]},\n",
       "  15: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(49.0400), tensor(120.3600)]},\n",
       "  16: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(53.5800), tensor(109.1300)]},\n",
       "  17: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(56.0100), tensor(104.6200)]},\n",
       "  18: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(59.7200), tensor(104.5800)]},\n",
       "  19: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(63.1100), tensor(132.4700)]},\n",
       "  20: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(66.5800), tensor(95.7800)]},\n",
       "  21: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(69.9300), tensor(109.0600)]},\n",
       "  22: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(73.7400), tensor(104.1400)]},\n",
       "  23: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(77.0300), tensor(98.7600)]},\n",
       "  24: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(80.5200), tensor(92.4300)]},\n",
       "  25: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(83.9500), tensor(100.5300)]},\n",
       "  26: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(87.7900), tensor(94.9800)]},\n",
       "  27: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(91.0100), tensor(98.1000)]},\n",
       "  29: {'probs': Categorical(probs: torch.Size([1000])),\n",
       "   'params': [tensor(98.3100), tensor(102.1000)]}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop_dist.distributions.keys() # only alpha because the trained model was conditioning only on this property\n",
    "prop_dist.distributions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sampling we have to define `n_nodes`: number of atoms in the generated molecule, and `n_frames`: number of values of `alpha` for which we are going to generate a molecule.\n",
    "\n",
    "We generate `n_frames` molecules with `n_frames` different values of `alpha` equally spaced between `min_alpha` and `max_alpha`.\n",
    "In this case all molecules generated have `n_nodes` atoms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qm9.sampling import sample_sweep_conditional\n",
    "\n",
    "one_hot, charges, x, node_mask = sample_sweep_conditional(args_gen, device, model, dataset_info, prop_dist, n_nodes=10, n_frames=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save generated molecule to xyz file\n",
    "import qm9.visualizer as vis\n",
    "\n",
    "epoch = 0\n",
    "id_from = 1\n",
    "\n",
    "vis.save_xyz_file(\n",
    "        'outputs/%s/analysis/run%s/' % (args.exp_name, epoch), one_hot, charges, x, dataset_info,\n",
    "        id_from, name='conditional', node_mask=node_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gif with 5 images\n"
     ]
    }
   ],
   "source": [
    "# visualize the `n_frames` different molecules with increasing value of `alpha`.\n",
    "vis.visualize_chain(\"outputs/%s/analysis/run%s/\" % (args.exp_name, epoch), dataset_info,\n",
    "                        wandb=None, mode='conditional', spheres_3d=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Qualitative modified to generate a molecule for a specific value of `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qm9.sampling import sample\n",
    "\n",
    "n_nodes = 10 # number of nodes/atoms\n",
    "value_of_alpha = 40\n",
    "\n",
    "nodesxsample = torch.tensor([n_nodes])\n",
    "# normalize the value of alpha\n",
    "mean, mad = prop_dist.normalizer['alpha']['mean'], prop_dist.normalizer['alpha']['mad']\n",
    "value_of_alpha = (value_of_alpha - mean) / mad\n",
    "\n",
    "# put context in right format\n",
    "context = []\n",
    "context_row = torch.tensor([value_of_alpha]).unsqueeze(1)\n",
    "context.append(context_row)\n",
    "context = torch.cat(context, dim=1).float().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7376]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot, charges, x, node_mask = sample(args_gen, device, model, dataset_info, prop_dist, nodesxsample=nodesxsample, context=context, fix_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save generated molecule to xyz file\n",
    "import qm9.visualizer as vis\n",
    "\n",
    "epoch = 0\n",
    "id_from = 1\n",
    "\n",
    "vis.save_xyz_file(\n",
    "        'outputs/%s/analysis/run%s/' % (args.exp_name, epoch), one_hot, charges, x, dataset_info,\n",
    "        id_from, name='conditional', node_mask=node_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gif with 1 images\n"
     ]
    }
   ],
   "source": [
    "vis.visualize_chain(\"outputs/%s/analysis/run%s/\" % (args.exp_name, epoch), dataset_info,\n",
    "                        wandb=None, mode='conditional', spheres_3d=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quantitative"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
