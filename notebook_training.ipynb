{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of **Training** EDM: E(3) Equivariant Diffusion Model for Molecule Generation in 3D.\n",
    "[Github repo](https://github.com/ehoogeboom/e3_diffusion_for_molecules)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main file `main_qm9.py`\n",
    "The training is triggered with a command like:\n",
    "```bash\n",
    "python main_qm9.py --n_epochs 3000 --exp_name edm_qm9 --n_stability_samples 1000 --diffusion_noise_schedule polynomial_2 --diffusion_noise_precision 1e-5 --diffusion_steps 1000 --diffusion_loss_type l2 --batch_size 64 --nf 256 --n_layers 9 --lr 1e-4 --normalize_factors [1,4,10] --test_epochs 20 --ema_decay 0.9999\n",
    "```\n",
    "Use `argparse` with several default values in case user doesn't explicitly passes them. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='E3Diffusion')\n",
    "parser.add_argument('--dataset', default='qm9')\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--num_workers', type=int, default=0)\n",
    "parser.add_argument('--filter_n_atoms', type=int, default=None)\n",
    "parser.add_argument('--datadir', type=str, default='qm9/temp')\n",
    "parser.add_argument('--remove_h', action='store_true')\n",
    "parser.add_argument('--include_charges', type=eval, default=True)\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qm9'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.datasets_config import get_dataset_info\n",
    "from qm9 import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['name', 'atom_encoder', 'atom_decoder', 'n_nodes', 'max_n_nodes', 'atom_types', 'distances', 'colors_dic', 'radius_dic', 'with_h'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_info = get_dataset_info(args.dataset, args.remove_h)\n",
    "dataset_info.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve QM9 dataloaders\n",
    "dataloaders, charge_scale = dataset.retrieve_dataloaders(args)\n",
    "data_dummy = next(iter(dataloaders['train']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "dict_keys(['train', 'valid', 'test'])\n",
      "train: 782\n",
      "valid: 139\n",
      "test: 103\n"
     ]
    }
   ],
   "source": [
    "print(charge_scale)\n",
    "print(dataloaders.keys())\n",
    "for key in dataloaders: print(f\"{key}: {len(dataloaders[key])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a look to a data-example `data_dummy`.\n",
    "\n",
    "This one has 128 molecules, with different number of atoms. Tensors of `positions` has 27 dimensions that is the maximum number of atoms in a molecule in this dataset. In the cases where a molecule has less, the last element are 0's.\n",
    "\n",
    "_conditioning_ is on a molecule property (i.e., single value per molecule): homo | lumo | alpha | gap | mu | Cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_atoms: torch.Size([128])\n",
      "charges: torch.Size([128, 27, 1])\n",
      "positions: torch.Size([128, 27, 3])\n",
      "index: torch.Size([128])\n",
      "A: torch.Size([128])\n",
      "B: torch.Size([128])\n",
      "C: torch.Size([128])\n",
      "mu: torch.Size([128])\n",
      "alpha: torch.Size([128])\n",
      "homo: torch.Size([128])\n",
      "lumo: torch.Size([128])\n",
      "gap: torch.Size([128])\n",
      "r2: torch.Size([128])\n",
      "zpve: torch.Size([128])\n",
      "U0: torch.Size([128])\n",
      "U: torch.Size([128])\n",
      "H: torch.Size([128])\n",
      "G: torch.Size([128])\n",
      "Cv: torch.Size([128])\n",
      "omega1: torch.Size([128])\n",
      "zpve_thermo: torch.Size([128])\n",
      "U0_thermo: torch.Size([128])\n",
      "U_thermo: torch.Size([128])\n",
      "H_thermo: torch.Size([128])\n",
      "G_thermo: torch.Size([128])\n",
      "Cv_thermo: torch.Size([128])\n",
      "one_hot: torch.Size([128, 27, 5])\n",
      "atom_mask: torch.Size([128, 27])\n",
      "edge_mask: torch.Size([93312, 1])\n"
     ]
    }
   ],
   "source": [
    "for key in data_dummy: print(f\"{key}: {data_dummy[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True, False, False, False, False, False])\n",
      "tensor(22)\n",
      "tensor([True])\n"
     ]
    }
   ],
   "source": [
    "print(data_dummy['atom_mask'][10])\n",
    "print(data_dummy['num_atoms'][10])\n",
    "print(data_dummy['edge_mask'][10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EGNN model\n",
    "‚ùóÔ∏èConditioning is pertinent here\n",
    "\n",
    "The model is composed of two submodules:\n",
    "\n",
    "__1. EGNN_dynamics_QM9:__ Equivariant GNN\n",
    "\n",
    "__2. EnVariationalDiffusion:__ Diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pertinent arguments for the EGNN model\n",
    "parser.add_argument(\"--conditioning\", nargs='+', default=[],\n",
    "                    help='arguments : homo | lumo | alpha | gap | mu | Cv' )\n",
    "parser.add_argument('--condition_time', type=eval, default=True)\n",
    "\n",
    "# pertinent for EGNN_dynamics_QM9\n",
    "parser.add_argument('--model', type=str, default='egnn_dynamics')\n",
    "parser.add_argument('--nf', type=int, default=128,\n",
    "                    help='number of layers')\n",
    "parser.add_argument('--n_layers', type=int, default=6,\n",
    "                    help='number of layers')\n",
    "parser.add_argument('--attention', type=eval, default=True,\n",
    "                    help='use attention in the EGNN')\n",
    "parser.add_argument('--tanh', type=eval, default=True,\n",
    "                    help='use tanh in the coord_mlp')\n",
    "parser.add_argument('--norm_constant', type=float, default=1,\n",
    "                    help='diff/(|diff| + norm_constant)')\n",
    "parser.add_argument('--inv_sublayers', type=int, default=1,\n",
    "                    help='number of layers')\n",
    "parser.add_argument('--sin_embedding', type=eval, default=False,\n",
    "                    help='whether using or not the sin embedding')\n",
    "parser.add_argument('--normalization_factor', type=float, default=1,\n",
    "                    help=\"Normalize the sum aggregation of EGNN\")\n",
    "parser.add_argument('--aggregation_method', type=str, default='sum',\n",
    "                    help='\"sum\" or \"mean\"')\n",
    "\n",
    "# pertinent for EnVariationalDiffusion\n",
    "parser.add_argument('--probabilistic_model', type=str, default='diffusion',\n",
    "                    help='diffusion')\n",
    "parser.add_argument('--diffusion_steps', type=int, default=500)\n",
    "parser.add_argument('--diffusion_noise_schedule', type=str, default='polynomial_2',\n",
    "                    help='learned, cosine')\n",
    "parser.add_argument('--diffusion_noise_precision', type=float, default=1e-5)\n",
    "parser.add_argument('--diffusion_loss_type', type=str, default='l2',\n",
    "                    help='vlb, l2')\n",
    "parser.add_argument('--normalize_factors', type=eval, default=[1, 4, 1],\n",
    "                    help='normalize factors for [x, categorical, integer]')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.context_node_nf = 0 # for the moment no conditioning\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qm9.models import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy of n_nodes: H[N] -2.475700616836548\n",
      "alphas2 [9.99990000e-01 9.99982000e-01 9.99958001e-01 9.99918003e-01\n",
      " 9.99862007e-01 9.99790014e-01 9.99702026e-01 9.99598046e-01\n",
      " 9.99478076e-01 9.99342118e-01 9.99190176e-01 9.99022254e-01\n",
      " 9.98838355e-01 9.98638484e-01 9.98422646e-01 9.98190846e-01\n",
      " 9.97943090e-01 9.97679383e-01 9.97399731e-01 9.97104143e-01\n",
      " 9.96792624e-01 9.96465182e-01 9.96121825e-01 9.95762562e-01\n",
      " 9.95387400e-01 9.94996350e-01 9.94589420e-01 9.94166620e-01\n",
      " 9.93727960e-01 9.93273451e-01 9.92803104e-01 9.92316930e-01\n",
      " 9.91814941e-01 9.91297149e-01 9.90763566e-01 9.90214206e-01\n",
      " 9.89649081e-01 9.89068205e-01 9.88471593e-01 9.87859258e-01\n",
      " 9.87231215e-01 9.86587480e-01 9.85928068e-01 9.85252996e-01\n",
      " 9.84562278e-01 9.83855933e-01 9.83133976e-01 9.82396427e-01\n",
      " 9.81643302e-01 9.80874619e-01 9.80090398e-01 9.79290657e-01\n",
      " 9.78475416e-01 9.77644695e-01 9.76798513e-01 9.75936891e-01\n",
      " 9.75059851e-01 9.74167412e-01 9.73259599e-01 9.72336431e-01\n",
      " 9.71397932e-01 9.70444124e-01 9.69475032e-01 9.68490677e-01\n",
      " 9.67491085e-01 9.66476280e-01 9.65446287e-01 9.64401130e-01\n",
      " 9.63340835e-01 9.62265428e-01 9.61174936e-01 9.60069385e-01\n",
      " 9.58948803e-01 9.57813215e-01 9.56662652e-01 9.55497140e-01\n",
      " 9.54316708e-01 9.53121386e-01 9.51911202e-01 9.50686187e-01\n",
      " 9.49446371e-01 9.48191784e-01 9.46922456e-01 9.45638420e-01\n",
      " 9.44339707e-01 9.43026349e-01 9.41698379e-01 9.40355829e-01\n",
      " 9.38998732e-01 9.37627123e-01 9.36241035e-01 9.34840502e-01\n",
      " 9.33425560e-01 9.31996243e-01 9.30552587e-01 9.29094628e-01\n",
      " 9.27622402e-01 9.26135946e-01 9.24635296e-01 9.23120491e-01\n",
      " 9.21591568e-01 9.20048565e-01 9.18491521e-01 9.16920476e-01\n",
      " 9.15335467e-01 9.13736535e-01 9.12123720e-01 9.10497064e-01\n",
      " 9.08856605e-01 9.07202386e-01 9.05534449e-01 9.03852835e-01\n",
      " 9.02157588e-01 9.00448749e-01 8.98726362e-01 8.96990470e-01\n",
      " 8.95241118e-01 8.93478350e-01 8.91702210e-01 8.89912744e-01\n",
      " 8.88109998e-01 8.86294016e-01 8.84464846e-01 8.82622534e-01\n",
      " 8.80767127e-01 8.78898672e-01 8.77017218e-01 8.75122812e-01\n",
      " 8.73215503e-01 8.71295340e-01 8.69362373e-01 8.67416650e-01\n",
      " 8.65458223e-01 8.63487142e-01 8.61503457e-01 8.59507220e-01\n",
      " 8.57498482e-01 8.55477296e-01 8.53443714e-01 8.51397789e-01\n",
      " 8.49339573e-01 8.47269121e-01 8.45186486e-01 8.43091724e-01\n",
      " 8.40984887e-01 8.38866033e-01 8.36735215e-01 8.34592490e-01\n",
      " 8.32437915e-01 8.30271545e-01 8.28093438e-01 8.25903651e-01\n",
      " 8.23702243e-01 8.21489271e-01 8.19264793e-01 8.17028869e-01\n",
      " 8.14781559e-01 8.12522921e-01 8.10253016e-01 8.07971904e-01\n",
      " 8.05679646e-01 8.03376304e-01 8.01061939e-01 7.98736613e-01\n",
      " 7.96400389e-01 7.94053329e-01 7.91695496e-01 7.89326954e-01\n",
      " 7.86947768e-01 7.84558000e-01 7.82157717e-01 7.79746982e-01\n",
      " 7.77325862e-01 7.74894423e-01 7.72452730e-01 7.70000850e-01\n",
      " 7.67538850e-01 7.65066798e-01 7.62584762e-01 7.60092809e-01\n",
      " 7.57591008e-01 7.55079428e-01 7.52558139e-01 7.50027209e-01\n",
      " 7.47486710e-01 7.44936711e-01 7.42377284e-01 7.39808499e-01\n",
      " 7.37230429e-01 7.34643144e-01 7.32046719e-01 7.29441225e-01\n",
      " 7.26826735e-01 7.24203324e-01 7.21571064e-01 7.18930031e-01\n",
      " 7.16280299e-01 7.13621943e-01 7.10955039e-01 7.08279662e-01\n",
      " 7.05595888e-01 7.02903795e-01 7.00203459e-01 6.97494957e-01\n",
      " 6.94778368e-01 6.92053769e-01 6.89321239e-01 6.86580857e-01\n",
      " 6.83832702e-01 6.81076855e-01 6.78313394e-01 6.75542400e-01\n",
      " 6.72763955e-01 6.69978139e-01 6.67185034e-01 6.64384722e-01\n",
      " 6.61577286e-01 6.58762807e-01 6.55941370e-01 6.53113058e-01\n",
      " 6.50277954e-01 6.47436144e-01 6.44587711e-01 6.41732740e-01\n",
      " 6.38871318e-01 6.36003530e-01 6.33129462e-01 6.30249200e-01\n",
      " 6.27362833e-01 6.24470446e-01 6.21572129e-01 6.18667968e-01\n",
      " 6.15758052e-01 6.12842471e-01 6.09921314e-01 6.06994670e-01\n",
      " 6.04062629e-01 6.01125282e-01 5.98182720e-01 5.95235034e-01\n",
      " 5.92282314e-01 5.89324654e-01 5.86362146e-01 5.83394882e-01\n",
      " 5.80422956e-01 5.77446461e-01 5.74465491e-01 5.71480140e-01\n",
      " 5.68490502e-01 5.65496674e-01 5.62498750e-01 5.59496826e-01\n",
      " 5.56490998e-01 5.53481364e-01 5.50468019e-01 5.47451061e-01\n",
      " 5.44430588e-01 5.41406698e-01 5.38379490e-01 5.35349062e-01\n",
      " 5.32315514e-01 5.29278945e-01 5.26239455e-01 5.23197145e-01\n",
      " 5.20152116e-01 5.17104468e-01 5.14054303e-01 5.11001724e-01\n",
      " 5.07946833e-01 5.04889731e-01 5.01830523e-01 4.98769312e-01\n",
      " 4.95706202e-01 4.92641297e-01 4.89574701e-01 4.86506520e-01\n",
      " 4.83436859e-01 4.80365824e-01 4.77293521e-01 4.74220056e-01\n",
      " 4.71145537e-01 4.68070071e-01 4.64993765e-01 4.61916728e-01\n",
      " 4.58839069e-01 4.55760895e-01 4.52682316e-01 4.49603443e-01\n",
      " 4.46524384e-01 4.43445250e-01 4.40366153e-01 4.37287202e-01\n",
      " 4.34208511e-01 4.31130190e-01 4.28052353e-01 4.24975111e-01\n",
      " 4.21898577e-01 4.18822866e-01 4.15748092e-01 4.12674367e-01\n",
      " 4.09601808e-01 4.06530529e-01 4.03460645e-01 4.00392272e-01\n",
      " 3.97325526e-01 3.94260525e-01 3.91197384e-01 3.88136221e-01\n",
      " 3.85077154e-01 3.82020301e-01 3.78965781e-01 3.75913711e-01\n",
      " 3.72864212e-01 3.69817403e-01 3.66773404e-01 3.63732335e-01\n",
      " 3.60694318e-01 3.57659473e-01 3.54627922e-01 3.51599786e-01\n",
      " 3.48575189e-01 3.45554252e-01 3.42537099e-01 3.39523853e-01\n",
      " 3.36514639e-01 3.33509580e-01 3.30508801e-01 3.27512426e-01\n",
      " 3.24520583e-01 3.21533395e-01 3.18550989e-01 3.15573492e-01\n",
      " 3.12601031e-01 3.09633733e-01 3.06671725e-01 3.03715136e-01\n",
      " 3.00764094e-01 2.97818728e-01 2.94879167e-01 2.91945541e-01\n",
      " 2.89017980e-01 2.86096614e-01 2.83181573e-01 2.80272990e-01\n",
      " 2.77370995e-01 2.74475721e-01 2.71587299e-01 2.68705862e-01\n",
      " 2.65831545e-01 2.62964478e-01 2.60104798e-01 2.57252637e-01\n",
      " 2.54408131e-01 2.51571415e-01 2.48742623e-01 2.45921892e-01\n",
      " 2.43109357e-01 2.40305156e-01 2.37509424e-01 2.34722300e-01\n",
      " 2.31943921e-01 2.29174425e-01 2.26413951e-01 2.23662637e-01\n",
      " 2.20920622e-01 2.18188046e-01 2.15465050e-01 2.12751773e-01\n",
      " 2.10048356e-01 2.07354940e-01 2.04671667e-01 2.01998678e-01\n",
      " 1.99336117e-01 1.96684125e-01 1.94042845e-01 1.91412422e-01\n",
      " 1.88792998e-01 1.86184719e-01 1.83587728e-01 1.81002170e-01\n",
      " 1.78428192e-01 1.75865938e-01 1.73315554e-01 1.70777188e-01\n",
      " 1.68250986e-01 1.65737095e-01 1.63235664e-01 1.60746839e-01\n",
      " 1.58270770e-01 1.55807605e-01 1.53357493e-01 1.50920584e-01\n",
      " 1.48497029e-01 1.46086976e-01 1.43690577e-01 1.41307984e-01\n",
      " 1.38939347e-01 1.36584819e-01 1.34244551e-01 1.31918696e-01\n",
      " 1.29607408e-01 1.27310840e-01 1.25029145e-01 1.22762477e-01\n",
      " 1.20510992e-01 1.18274845e-01 1.16054189e-01 1.13849182e-01\n",
      " 1.11659980e-01 1.09486738e-01 1.07329614e-01 1.05188764e-01\n",
      " 1.03064347e-01 1.00956521e-01 9.88654439e-02 9.67912743e-02\n",
      " 9.47341717e-02 9.26942954e-02 9.06718055e-02 8.86668624e-02\n",
      " 8.66796266e-02 8.47102593e-02 8.27589219e-02 8.08257763e-02\n",
      " 7.89109848e-02 7.70147099e-02 7.51371146e-02 7.32783625e-02\n",
      " 7.14386171e-02 6.96180427e-02 6.78168038e-02 6.60350654e-02\n",
      " 6.42729927e-02 6.25307515e-02 6.08085078e-02 5.91064280e-02\n",
      " 5.74246791e-02 5.57634283e-02 5.41228431e-02 5.25030916e-02\n",
      " 5.09043421e-02 4.93267634e-02 4.77705247e-02 4.62357955e-02\n",
      " 4.47227457e-02 4.32315456e-02 4.17623658e-02 4.03153776e-02\n",
      " 3.88907522e-02 3.74886616e-02 3.61092780e-02 3.47527739e-02\n",
      " 3.34193225e-02 3.21090969e-02 3.08222710e-02 2.95590190e-02\n",
      " 2.83195153e-02 2.71039349e-02 2.59124531e-02 2.47452455e-02\n",
      " 2.36024881e-02 2.24843576e-02 2.13910305e-02 2.03226843e-02\n",
      " 1.92794965e-02 1.82616450e-02 1.72693082e-02 1.63026649e-02\n",
      " 1.53618942e-02 1.44471756e-02 1.35586890e-02 1.26966148e-02\n",
      " 1.18611335e-02 1.10524262e-02 1.02706744e-02 9.51605988e-03\n",
      " 8.78876484e-03 8.08897187e-03 7.41686396e-03 6.77262444e-03\n",
      " 6.15643707e-03 5.56848596e-03 5.00895563e-03 4.47803097e-03\n",
      " 3.97589726e-03 3.50274014e-03 3.05874568e-03 2.64410029e-03\n",
      " 2.25899080e-03 1.90360438e-03 1.57812864e-03 1.28275152e-03\n",
      " 1.01766138e-03 7.83046955e-04 5.79097354e-04 4.06002080e-04\n",
      " 2.63951017e-04 1.53134433e-04 7.37429811e-05 2.59676966e-05\n",
      " 1.00159677e-05]\n",
      "gamma [-1.15129155e+01 -1.09251306e+01 -1.00778203e+01 -9.40874268e+00\n",
      " -8.88816710e+00 -8.46825969e+00 -8.11820797e+00 -7.81877150e+00\n",
      " -7.55746608e+00 -7.32582677e+00 -7.11788346e+00 -6.92928201e+00\n",
      " -6.75675569e+00 -6.59779406e+00 -6.45042792e+00 -6.31308514e+00\n",
      " -6.18449116e+00 -6.06359867e+00 -5.94953689e+00 -5.84157408e+00\n",
      " -5.73908957e+00 -5.64155244e+00 -5.54850500e+00 -5.45955000e+00\n",
      " -5.37434042e+00 -5.29257140e+00 -5.21397364e+00 -5.13830814e+00\n",
      " -5.06536178e+00 -4.99494375e+00 -4.92688250e+00 -4.86102331e+00\n",
      " -4.79722608e+00 -4.73536362e+00 -4.67532003e+00 -4.61698950e+00\n",
      " -4.56027508e+00 -4.50508778e+00 -4.45134570e+00 -4.39897331e+00\n",
      " -4.34790077e+00 -4.29806342e+00 -4.24940125e+00 -4.20185848e+00\n",
      " -4.15538317e+00 -4.10992684e+00 -4.06544425e+00 -4.02189301e+00\n",
      " -3.97923346e+00 -3.93742835e+00 -3.89644268e+00 -3.85624355e+00\n",
      " -3.81679995e+00 -3.77808264e+00 -3.74006402e+00 -3.70271801e+00\n",
      " -3.66601992e+00 -3.62994639e+00 -3.59447526e+00 -3.55958551e+00\n",
      " -3.52525717e+00 -3.49147127e+00 -3.45820974e+00 -3.42545540e+00\n",
      " -3.39319187e+00 -3.36140352e+00 -3.33007545e+00 -3.29919341e+00\n",
      " -3.26874381e+00 -3.23871363e+00 -3.20909042e+00 -3.17986224e+00\n",
      " -3.15101768e+00 -3.12254577e+00 -3.09443601e+00 -3.06667831e+00\n",
      " -3.03926297e+00 -3.01218069e+00 -2.98542251e+00 -2.95897981e+00\n",
      " -2.93284431e+00 -2.90700803e+00 -2.88146327e+00 -2.85620263e+00\n",
      " -2.83121894e+00 -2.80650533e+00 -2.78205513e+00 -2.75786192e+00\n",
      " -2.73391949e+00 -2.71022183e+00 -2.68676316e+00 -2.66353786e+00\n",
      " -2.64054050e+00 -2.61776583e+00 -2.59520877e+00 -2.57286439e+00\n",
      " -2.55072792e+00 -2.52879473e+00 -2.50706034e+00 -2.48552039e+00\n",
      " -2.46417067e+00 -2.44300707e+00 -2.42202563e+00 -2.40122247e+00\n",
      " -2.38059385e+00 -2.36013612e+00 -2.33984573e+00 -2.31971924e+00\n",
      " -2.29975330e+00 -2.27994464e+00 -2.26029009e+00 -2.24078657e+00\n",
      " -2.22143107e+00 -2.20222065e+00 -2.18315246e+00 -2.16422373e+00\n",
      " -2.14543174e+00 -2.12677385e+00 -2.10824749e+00 -2.08985013e+00\n",
      " -2.07157934e+00 -2.05343271e+00 -2.03540792e+00 -2.01750268e+00\n",
      " -1.99971476e+00 -1.98204200e+00 -1.96448226e+00 -1.94703347e+00\n",
      " -1.92969361e+00 -1.91246068e+00 -1.89533275e+00 -1.87830792e+00\n",
      " -1.86138434e+00 -1.84456020e+00 -1.82783370e+00 -1.81120312e+00\n",
      " -1.79466676e+00 -1.77822294e+00 -1.76187003e+00 -1.74560644e+00\n",
      " -1.72943060e+00 -1.71334097e+00 -1.69733604e+00 -1.68141435e+00\n",
      " -1.66557444e+00 -1.64981490e+00 -1.63413434e+00 -1.61853138e+00\n",
      " -1.60300470e+00 -1.58755297e+00 -1.57217491e+00 -1.55686925e+00\n",
      " -1.54163474e+00 -1.52647017e+00 -1.51137433e+00 -1.49634605e+00\n",
      " -1.48138416e+00 -1.46648753e+00 -1.45165504e+00 -1.43688559e+00\n",
      " -1.42217810e+00 -1.40753150e+00 -1.39294475e+00 -1.37841681e+00\n",
      " -1.36394669e+00 -1.34953337e+00 -1.33517587e+00 -1.32087324e+00\n",
      " -1.30662452e+00 -1.29242877e+00 -1.27828507e+00 -1.26419252e+00\n",
      " -1.25015021e+00 -1.23615727e+00 -1.22221282e+00 -1.20831600e+00\n",
      " -1.19446598e+00 -1.18066192e+00 -1.16690300e+00 -1.15318840e+00\n",
      " -1.13951732e+00 -1.12588899e+00 -1.11230260e+00 -1.09875741e+00\n",
      " -1.08525264e+00 -1.07178756e+00 -1.05836141e+00 -1.04497347e+00\n",
      " -1.03162301e+00 -1.01830932e+00 -1.00503169e+00 -9.91789438e-01\n",
      " -9.78581858e-01 -9.65408273e-01 -9.52268010e-01 -9.39160402e-01\n",
      " -9.26084788e-01 -9.13040516e-01 -9.00026940e-01 -8.87043420e-01\n",
      " -8.74089323e-01 -8.61164023e-01 -8.48266898e-01 -8.35397335e-01\n",
      " -8.22554723e-01 -8.09738460e-01 -7.96947946e-01 -7.84182591e-01\n",
      " -7.71441804e-01 -7.58725005e-01 -7.46031614e-01 -7.33361059e-01\n",
      " -7.20712771e-01 -7.08086186e-01 -6.95480742e-01 -6.82895885e-01\n",
      " -6.70331063e-01 -6.57785727e-01 -6.45259332e-01 -6.32751339e-01\n",
      " -6.20261210e-01 -6.07788411e-01 -5.95332410e-01 -5.82892681e-01\n",
      " -5.70468700e-01 -5.58059943e-01 -5.45665893e-01 -5.33286033e-01\n",
      " -5.20919850e-01 -5.08566831e-01 -4.96226469e-01 -4.83898256e-01\n",
      " -4.71581688e-01 -4.59276262e-01 -4.46981478e-01 -4.34696836e-01\n",
      " -4.22421840e-01 -4.10155993e-01 -3.97898802e-01 -3.85649773e-01\n",
      " -3.73408415e-01 -3.61174239e-01 -3.48946754e-01 -3.36725473e-01\n",
      " -3.24509907e-01 -3.12299572e-01 -3.00093980e-01 -2.87892646e-01\n",
      " -2.75695086e-01 -2.63500815e-01 -2.51309349e-01 -2.39120204e-01\n",
      " -2.26932897e-01 -2.14746943e-01 -2.02561860e-01 -1.90377161e-01\n",
      " -1.78192365e-01 -1.66006985e-01 -1.53820536e-01 -1.41632534e-01\n",
      " -1.29442490e-01 -1.17249919e-01 -1.05054332e-01 -9.28552399e-02\n",
      " -8.06521526e-02 -6.84445791e-02 -5.62320266e-02 -4.40140013e-02\n",
      " -3.17900077e-02 -1.95595489e-02 -7.32212627e-03  4.92276070e-03\n",
      "  1.71756143e-02  2.94369390e-02  4.17072410e-02  5.39870292e-02\n",
      "  6.62768145e-02  7.85771104e-02  9.08884327e-02  1.03211300e-01\n",
      "  1.15546234e-01  1.27893759e-01  1.40254403e-01  1.52628695e-01\n",
      "  1.65017169e-01  1.77420363e-01  1.89838818e-01  2.02273077e-01\n",
      "  2.14723688e-01  2.27191204e-01  2.39676180e-01  2.52179176e-01\n",
      "  2.64700758e-01  2.77241493e-01  2.89801955e-01  3.02382722e-01\n",
      "  3.14984378e-01  3.27607510e-01  3.40252711e-01  3.52920581e-01\n",
      "  3.65611723e-01  3.78326747e-01  3.91066268e-01  4.03830909e-01\n",
      "  4.16621296e-01  4.29438063e-01  4.42281852e-01  4.55153310e-01\n",
      "  4.68053090e-01  4.80981854e-01  4.93940271e-01  5.06929016e-01\n",
      "  5.19948774e-01  5.33000235e-01  5.46084100e-01  5.59201076e-01\n",
      "  5.72351881e-01  5.85537239e-01  5.98757885e-01  6.12014563e-01\n",
      "  6.25308026e-01  6.38639036e-01  6.52008368e-01  6.65416804e-01\n",
      "  6.78865138e-01  6.92354176e-01  7.05884732e-01  7.19457635e-01\n",
      "  7.33073724e-01  7.46733850e-01  7.60438876e-01  7.74189679e-01\n",
      "  7.87987149e-01  8.01832188e-01  8.15725713e-01  8.29668656e-01\n",
      "  8.43661960e-01  8.57706587e-01  8.71803513e-01  8.85953729e-01\n",
      "  9.00158242e-01  9.14418077e-01  9.28734275e-01  9.43107896e-01\n",
      "  9.57540015e-01  9.72031730e-01  9.86584154e-01  1.00119842e+00\n",
      "  1.01587569e+00  1.03061713e+00  1.04542394e+00  1.06029734e+00\n",
      "  1.07523856e+00  1.09024888e+00  1.10532959e+00  1.12048198e+00\n",
      "  1.13570741e+00  1.15100723e+00  1.16638284e+00  1.18183566e+00\n",
      "  1.19736713e+00  1.21297872e+00  1.22867195e+00  1.24444834e+00\n",
      "  1.26030948e+00  1.27625695e+00  1.29229241e+00  1.30841751e+00\n",
      "  1.32463397e+00  1.34094352e+00  1.35734796e+00  1.37384910e+00\n",
      "  1.39044881e+00  1.40714899e+00  1.42395160e+00  1.44085862e+00\n",
      "  1.45787210e+00  1.47499412e+00  1.49222683e+00  1.50957241e+00\n",
      "  1.52703311e+00  1.54461123e+00  1.56230911e+00  1.58012918e+00\n",
      "  1.59807390e+00  1.61614582e+00  1.63434753e+00  1.65268170e+00\n",
      "  1.67115108e+00  1.68975848e+00  1.70850678e+00  1.72739896e+00\n",
      "  1.74643804e+00  1.76562717e+00  1.78496957e+00  1.80446853e+00\n",
      "  1.82412746e+00  1.84394986e+00  1.86393934e+00  1.88409958e+00\n",
      "  1.90443442e+00  1.92494778e+00  1.94564371e+00  1.96652638e+00\n",
      "  1.98760009e+00  2.00886928e+00  2.03033853e+00  2.05201255e+00\n",
      "  2.07389622e+00  2.09599457e+00  2.11831280e+00  2.14085630e+00\n",
      "  2.16363060e+00  2.18664146e+00  2.20989481e+00  2.23339682e+00\n",
      "  2.25715386e+00  2.28117251e+00  2.30545962e+00  2.33002229e+00\n",
      "  2.35486785e+00  2.38000395e+00  2.40543851e+00  2.43117976e+00\n",
      "  2.45723624e+00  2.48361686e+00  2.51033085e+00  2.53738786e+00\n",
      "  2.56479791e+00  2.59257144e+00  2.62071935e+00  2.64925300e+00\n",
      "  2.67818425e+00  2.70752550e+00  2.73728968e+00  2.76749035e+00\n",
      "  2.79814167e+00  2.82925849e+00  2.86085637e+00  2.89295162e+00\n",
      "  2.92556137e+00  2.95870360e+00  2.99239724e+00  3.02666218e+00\n",
      "  3.06151939e+00  3.09699096e+00  3.13310020e+00  3.16987174e+00\n",
      "  3.20733159e+00  3.24550732e+00  3.28442809e+00  3.32412487e+00\n",
      "  3.36463052e+00  3.40597999e+00  3.44821050e+00  3.49136168e+00\n",
      "  3.53547588e+00  3.58059834e+00  3.62677752e+00  3.67406536e+00\n",
      "  3.72251765e+00  3.77219445e+00  3.82316044e+00  3.87548553e+00\n",
      "  3.92924534e+00  3.98452188e+00  4.04140428e+00  4.09998968e+00\n",
      "  4.16038413e+00  4.22270379e+00  4.28707623e+00  4.35364197e+00\n",
      "  4.42255628e+00  4.49399135e+00  4.56813881e+00  4.64521277e+00\n",
      "  4.72545348e+00  4.80913178e+00  4.89655445e+00  4.98807095e+00\n",
      "  5.08408160e+00  5.18504803e+00  5.29150630e+00  5.40408376e+00\n",
      "  5.52352101e+00  5.65070083e+00  5.78668692e+00  5.93277682e+00\n",
      "  6.09057557e+00  6.26210073e+00  6.44993617e+00  6.65746431e+00\n",
      "  6.88922987e+00  7.15153454e+00  7.45346069e+00  7.80874619e+00\n",
      "  8.23948303e+00  8.78404123e+00  9.51485099e+00  1.05586313e+01\n",
      "  1.15113200e+01]\n"
     ]
    }
   ],
   "source": [
    "model, nodes_dist, prop_dist = get_model(args, device, dataset_info, dataloaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnVariationalDiffusion(\n",
       "  (gamma): PredefinedNoiseSchedule()\n",
       "  (dynamics): EGNN_dynamics_QM9(\n",
       "    (egnn): EGNN(\n",
       "      (embedding): Linear(in_features=7, out_features=128, bias=True)\n",
       "      (embedding_out): Linear(in_features=128, out_features=7, bias=True)\n",
       "      (e_block_0): EquivariantBlock(\n",
       "        (gcl_0): GCL(\n",
       "          (edge_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "          )\n",
       "          (node_mlp): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (att_mlp): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (gcl_equiv): EquivariantUpdate(\n",
       "          (coord_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "            (4): Linear(in_features=128, out_features=1, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (e_block_1): EquivariantBlock(\n",
       "        (gcl_0): GCL(\n",
       "          (edge_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "          )\n",
       "          (node_mlp): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (att_mlp): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (gcl_equiv): EquivariantUpdate(\n",
       "          (coord_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "            (4): Linear(in_features=128, out_features=1, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (e_block_2): EquivariantBlock(\n",
       "        (gcl_0): GCL(\n",
       "          (edge_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "          )\n",
       "          (node_mlp): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (att_mlp): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (gcl_equiv): EquivariantUpdate(\n",
       "          (coord_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "            (4): Linear(in_features=128, out_features=1, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (e_block_3): EquivariantBlock(\n",
       "        (gcl_0): GCL(\n",
       "          (edge_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "          )\n",
       "          (node_mlp): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (att_mlp): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (gcl_equiv): EquivariantUpdate(\n",
       "          (coord_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "            (4): Linear(in_features=128, out_features=1, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (e_block_4): EquivariantBlock(\n",
       "        (gcl_0): GCL(\n",
       "          (edge_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "          )\n",
       "          (node_mlp): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (att_mlp): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (gcl_equiv): EquivariantUpdate(\n",
       "          (coord_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "            (4): Linear(in_features=128, out_features=1, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (e_block_5): EquivariantBlock(\n",
       "        (gcl_0): GCL(\n",
       "          (edge_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "          )\n",
       "          (node_mlp): Sequential(\n",
       "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (att_mlp): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (gcl_equiv): EquivariantUpdate(\n",
       "          (coord_mlp): Sequential(\n",
       "            (0): Linear(in_features=258, out_features=128, bias=True)\n",
       "            (1): SiLU()\n",
       "            (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (3): SiLU()\n",
       "            (4): Linear(in_features=128, out_features=1, bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'equivariant_diffusion.en_diffusion.EnVariationalDiffusion'>\n",
      "<class 'egnn.models.EGNN_dynamics_QM9'>\n",
      "egnn_dynamics\n",
      "<class 'egnn.egnn_new.EGNN'>\n",
      "number of layers EGNN (all Equivariant blocks): 6\n",
      "<class 'egnn.egnn_new.EquivariantBlock'>\n",
      "number of layers Equivariant block 0: 1\n",
      "<class 'egnn.egnn_new.GCL'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "print(type(model.dynamics))\n",
    "print(model.dynamics.mode)\n",
    "print(type(model.dynamics.egnn))\n",
    "print(f\"number of layers EGNN (all Equivariant blocks): {model.dynamics.egnn.n_layers}\")\n",
    "print(type(model.dynamics.egnn.e_block_0))\n",
    "print(f\"number of layers Equivariant block 0: {model.dynamics.egnn.e_block_0.n_layers}\")\n",
    "print(type(model.dynamics.egnn.e_block_0.gcl_0))\n",
    "print(f\"number of layers GCL in Equivariant block 0: {model.dynamics.egnn.e_block_0.n_layers}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--lr', type=float, default=2e-4)\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qm9.models import get_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = get_optim(args, model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Additional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser.add_argument('--ema_decay', type=float, default=0.999,\n",
    "                    help='Amount of EMA decay, 0 means off. A reasonable value is 0.999.')\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data parallel model\n",
    "model_dp = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ema\n",
    "from equivariant_diffusion import utils as flow_utils\n",
    "import copy\n",
    "model_ema = copy.deepcopy(model)\n",
    "ema = flow_utils.EMA(args.ema_decay)\n",
    "model_ema_dp = model_ema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training üëü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some variables necessary in case conditioning\n",
    "property_norms = None\n",
    "\n",
    "import utils\n",
    "gradnorm_queue = utils.Queue()\n",
    "gradnorm_queue.add(3000)  # Add large value that will be flushed\n",
    "\n",
    "parser.add_argument('--augment_noise', type=float, default=0)\n",
    "parser.add_argument('--data_augmentation', type=eval, default=False, help='use attention in the EGNN')\n",
    "parser.add_argument('--ode_regularization', type=float, default=1e-3)\n",
    "parser.add_argument('--clip_grad', type=eval, default=True, help='True | False')\n",
    "parser.add_argument('--test_epochs', type=int, default=10)\n",
    "parser.add_argument('--visualize_every_batch', type=int, default=1e8,\n",
    "                    help=\"Can be used to visualize multiple times per epoch\")\n",
    "parser.add_argument('--break_train_epoch', type=eval, default=False,\n",
    "                    help='True | False')\n",
    "parser.add_argument('--n_report_steps', type=int, default=1)\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/luisaorozco/Documents/Projects/DeepMolGen/e3_diffusion_for_molecules/wandb/run-20230608_145555-om7a7q2o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/luisaforozco/e3_diffusion-notebook/runs/om7a7q2o' target=\"_blank\">glorious-energy-1</a></strong> to <a href='https://wandb.ai/luisaforozco/e3_diffusion-notebook' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/luisaforozco/e3_diffusion-notebook' target=\"_blank\">https://wandb.ai/luisaforozco/e3_diffusion-notebook</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/luisaforozco/e3_diffusion-notebook/runs/om7a7q2o' target=\"_blank\">https://wandb.ai/luisaforozco/e3_diffusion-notebook/runs/om7a7q2o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/luisaforozco/e3_diffusion-notebook/runs/om7a7q2o?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x3503dd290>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb\n",
    "import wandb\n",
    "wandb.init(**{'project': 'e3_diffusion-notebook', 'config': args})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, iter: 0/782, Loss 2.82, NLL: 2.82, RegTerm: 0.0, GradNorm: 48.3\n",
      "Epoch: 0, iter: 1/782, Loss 2.89, NLL: 2.89, RegTerm: 0.0, GradNorm: 12.0\n",
      "Epoch: 0, iter: 2/782, Loss 2.79, NLL: 2.79, RegTerm: 0.0, GradNorm: 19.5\n",
      "Epoch: 0, iter: 3/782, Loss 2.89, NLL: 2.89, RegTerm: 0.0, GradNorm: 23.7\n",
      "Epoch: 0, iter: 4/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 18.5\n",
      "Epoch: 0, iter: 5/782, Loss 2.79, NLL: 2.79, RegTerm: 0.0, GradNorm: 16.2\n",
      "Epoch: 0, iter: 6/782, Loss 2.79, NLL: 2.79, RegTerm: 0.0, GradNorm: 10.6\n",
      "Epoch: 0, iter: 7/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 0, iter: 8/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 0, iter: 9/782, Loss 2.76, NLL: 2.76, RegTerm: 0.0, GradNorm: 8.7\n",
      "Epoch: 0, iter: 10/782, Loss 2.74, NLL: 2.74, RegTerm: 0.0, GradNorm: 9.3\n",
      "Epoch: 0, iter: 11/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 10.6\n",
      "Epoch: 0, iter: 12/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 0, iter: 13/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 0, iter: 14/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 15/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 16/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 0, iter: 17/782, Loss 2.75, NLL: 2.75, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 0, iter: 18/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 0, iter: 19/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 0, iter: 20/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 0, iter: 21/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 15.7\n",
      "Epoch: 0, iter: 22/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 23/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 24/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 25/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 26/782, Loss 2.84, NLL: 2.84, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 27/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 28/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 29/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 26.1\n",
      "Epoch: 0, iter: 30/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 31/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 32/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 0, iter: 33/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 34/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 35/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 36/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 0, iter: 37/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 38/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 39/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 40/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 41/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 42/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 43/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 44/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 45/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 0, iter: 46/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 47/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 48/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 49/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 0.5\n",
      "Epoch: 0, iter: 50/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 51/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 52/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 53/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 54/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 55/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 0, iter: 56/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 57/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 58/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 0.4\n",
      "Epoch: 0, iter: 59/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 60/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 61/782, Loss 2.74, NLL: 2.74, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 62/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 63/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 64/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 65/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 66/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 67/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 68/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 0, iter: 69/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 70/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 71/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 72/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 73/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 74/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 75/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 76/782, Loss 2.76, NLL: 2.76, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 77/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 78/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 79/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 1.6\n",
      "Clipped gradient with value 5.5 while allowed 3.9\n",
      "Epoch: 0, iter: 80/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 0, iter: 81/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 82/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 83/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 84/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 85/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 86/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 87/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 88/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 89/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 90/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 91/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 92/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 93/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 94/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 95/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 96/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 97/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 98/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 99/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.4\n",
      "Epoch: 0, iter: 100/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 101/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 102/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 103/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 0, iter: 104/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 105/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 106/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 107/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 108/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 109/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 110/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 0, iter: 111/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 112/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 113/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 114/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 115/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 116/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 117/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 118/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 119/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 120/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 121/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 122/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 123/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 124/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 125/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 126/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 127/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 128/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 129/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 130/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 131/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 132/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 133/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 134/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 135/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.7\n",
      "Clipped gradient with value 4.2 while allowed 3.4\n",
      "Epoch: 0, iter: 136/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 0, iter: 137/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Clipped gradient with value 5.0 while allowed 3.5\n",
      "Epoch: 0, iter: 138/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 0, iter: 139/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 140/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 141/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 142/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 143/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 144/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 145/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 146/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 147/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 148/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 149/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 150/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 151/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 152/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 153/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 154/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 155/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 156/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 157/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 158/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 159/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 160/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 161/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 162/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 163/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 164/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 165/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 166/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 167/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 168/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 169/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 170/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 171/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 172/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 173/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 174/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 175/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 176/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 177/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 178/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 179/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 180/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 181/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 182/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 183/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 184/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 185/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 186/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 187/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 188/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 189/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 190/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 191/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 192/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 193/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 194/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 195/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 196/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 197/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 198/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 199/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 200/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 201/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 202/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 203/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 204/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 205/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 206/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 207/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 208/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 209/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 210/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 211/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 0, iter: 212/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 213/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 214/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 215/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 216/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 217/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 218/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 219/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 220/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Clipped gradient with value 5.0 while allowed 4.5\n",
      "Epoch: 0, iter: 221/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 0, iter: 222/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 223/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 224/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 225/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 0, iter: 226/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 227/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 228/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 229/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 230/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 231/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 232/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 233/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 234/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 235/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 236/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 237/782, Loss 2.78, NLL: 2.78, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 238/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 239/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 240/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 241/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 242/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 243/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 244/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 245/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 246/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 247/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 248/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 249/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 250/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 0, iter: 251/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 252/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 253/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.9\n",
      "Clipped gradient with value 6.3 while allowed 5.6\n",
      "Epoch: 0, iter: 254/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 0, iter: 255/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 0, iter: 256/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.6\n",
      "Clipped gradient with value 6.4 while allowed 6.0\n",
      "Epoch: 0, iter: 257/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 0, iter: 258/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 259/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 260/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 261/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 262/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 263/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 264/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 265/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 266/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 267/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 268/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 269/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 270/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 271/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 272/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 273/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 274/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 275/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 276/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 277/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 278/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 279/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 280/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 281/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 282/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 283/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 284/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 285/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 286/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 287/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 288/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 0, iter: 289/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 290/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 291/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 292/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 293/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 294/782, Loss 2.74, NLL: 2.74, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 295/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 296/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 297/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 298/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 299/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 300/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 301/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 302/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 303/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 304/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 0, iter: 305/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 306/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 0, iter: 307/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 308/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 0, iter: 309/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 310/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 311/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 312/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 313/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 314/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 315/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 316/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 317/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 318/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 319/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 320/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 321/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 322/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 323/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 324/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 325/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 326/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 327/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 328/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 329/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 330/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 331/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 332/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 333/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 334/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 335/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 336/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 337/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 338/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 339/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 340/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 341/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 342/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 343/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 344/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 345/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 0, iter: 346/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Clipped gradient with value 6.5 while allowed 5.7\n",
      "Epoch: 0, iter: 347/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 0, iter: 348/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 349/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 0, iter: 350/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 351/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 352/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 353/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 354/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 355/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 356/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 357/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 358/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 359/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 360/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 361/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 0, iter: 362/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 363/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 0, iter: 364/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 365/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 366/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 367/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 368/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 369/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 370/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 371/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 372/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 373/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 374/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 375/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 0, iter: 376/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 377/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 378/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 379/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 380/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 381/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 382/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 383/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 384/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 385/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 386/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 387/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 388/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 389/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 390/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 391/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 392/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 393/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 394/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 395/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 396/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 397/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 0, iter: 398/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 399/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 400/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 401/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 402/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 403/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 404/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 405/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 406/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 407/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 408/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 409/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 410/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Clipped gradient with value 5.8 while allowed 5.1\n",
      "Epoch: 0, iter: 411/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 0, iter: 412/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 0, iter: 413/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 0, iter: 414/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 415/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 416/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 417/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 418/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 419/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 420/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 421/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 422/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 423/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 424/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 425/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 426/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 427/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 428/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 429/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 430/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 0, iter: 431/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 432/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 433/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 434/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 435/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 436/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 437/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 438/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 439/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 440/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 441/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 442/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 443/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 444/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 445/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 446/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 447/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 448/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 449/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 450/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 451/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 452/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 0, iter: 453/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 454/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 0, iter: 455/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 456/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 0, iter: 457/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 458/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 0, iter: 459/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 460/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 0, iter: 461/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 462/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 463/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 464/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 465/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 466/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 467/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 468/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 0, iter: 469/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 470/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 471/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 472/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 473/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 474/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 475/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 476/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 477/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 478/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 479/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 480/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 481/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 482/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 483/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 484/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 485/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 486/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 487/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 488/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 489/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 490/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 491/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 0, iter: 492/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 493/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 0, iter: 494/782, Loss 2.75, NLL: 2.75, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 495/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 496/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 497/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 498/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 499/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 500/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 501/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.8\n",
      "Clipped gradient with value 7.6 while allowed 6.3\n",
      "Epoch: 0, iter: 502/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 0, iter: 503/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.6\n",
      "Clipped gradient with value 9.0 while allowed 6.5\n",
      "Epoch: 0, iter: 504/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 9.0\n",
      "Epoch: 0, iter: 505/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 0, iter: 506/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 0, iter: 507/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 0, iter: 508/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 509/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 0, iter: 510/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 511/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 0, iter: 512/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 513/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 0, iter: 514/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 0, iter: 515/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 516/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 0, iter: 517/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 0, iter: 518/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 0, iter: 519/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 520/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 521/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 522/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 523/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 524/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 525/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 526/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 527/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 528/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 0, iter: 529/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 0, iter: 530/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 0, iter: 531/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 532/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 0, iter: 533/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 534/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 535/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 536/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 537/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 538/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 539/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 540/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 541/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 542/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 0, iter: 543/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 544/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 545/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 546/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 0, iter: 547/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 548/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 549/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 550/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 551/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 552/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 553/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 554/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 555/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 556/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 557/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 558/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 559/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 560/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 561/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 562/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 563/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 564/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 565/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 566/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 567/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 568/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 569/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 570/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 571/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 572/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 573/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 574/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 0, iter: 575/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 576/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 577/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 0, iter: 578/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 0, iter: 579/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 580/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 0, iter: 581/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 0, iter: 582/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 583/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 584/782, Loss 2.77, NLL: 2.77, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 585/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 586/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 587/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 588/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 0, iter: 589/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 590/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 591/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 592/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 593/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 0, iter: 594/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 0, iter: 595/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 596/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 597/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 598/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 0, iter: 599/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 600/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 0, iter: 601/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 602/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 0, iter: 603/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 0, iter: 604/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 0, iter: 605/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 606/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 607/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 608/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 609/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 610/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 611/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 612/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 613/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 614/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 615/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 0, iter: 616/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 617/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 618/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 619/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 620/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 0, iter: 621/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 622/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 623/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 0, iter: 624/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 625/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 0, iter: 626/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 627/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 0, iter: 628/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 629/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 0, iter: 630/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 631/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 632/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 0, iter: 633/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 0, iter: 634/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 635/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 0, iter: 636/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 637/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 638/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 0, iter: 639/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 640/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 641/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 642/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 0, iter: 643/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 0, iter: 644/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 645/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 0, iter: 646/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 647/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 0, iter: 648/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 649/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 0, iter: 650/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 651/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 652/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 0, iter: 653/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 654/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 655/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 0, iter: 656/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 657/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 658/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 659/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 660/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 0, iter: 661/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 662/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 663/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 664/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 665/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 666/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 0, iter: 667/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 0, iter: 668/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 0, iter: 669/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 670/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 671/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 672/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 673/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 674/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.5\n",
      "Clipped gradient with value 7.5 while allowed 7.1\n",
      "Epoch: 0, iter: 675/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 0, iter: 676/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 677/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 0, iter: 678/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 0, iter: 679/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 680/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 681/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 0, iter: 682/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 0, iter: 683/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 0, iter: 684/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 0, iter: 685/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 0, iter: 686/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 687/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 688/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 689/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 0, iter: 690/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 0, iter: 691/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 0, iter: 692/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 0, iter: 693/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 0, iter: 694/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 695/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 696/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 697/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 698/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 699/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 0, iter: 700/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 0, iter: 701/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 0, iter: 702/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.8\n",
      "Clipped gradient with value 21.8 while allowed 7.9\n",
      "Epoch: 0, iter: 703/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 21.8\n",
      "Epoch: 0, iter: 704/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 0, iter: 705/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 706/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 707/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 708/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 709/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 710/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 711/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 712/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 0, iter: 713/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 714/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 0, iter: 715/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 716/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 0, iter: 717/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 0, iter: 718/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 719/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 720/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 721/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 0, iter: 722/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 723/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 724/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 725/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 726/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 727/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 728/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 729/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 730/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 0, iter: 731/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 732/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 733/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 0, iter: 734/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 0, iter: 735/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 736/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 737/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 738/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 739/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 740/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 741/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 0, iter: 742/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 743/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 744/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 0, iter: 745/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 0, iter: 746/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 0, iter: 747/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 0, iter: 748/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 0, iter: 749/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 0, iter: 750/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 0, iter: 751/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 0, iter: 752/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 0, iter: 753/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 0, iter: 754/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 755/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 756/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 757/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 0, iter: 758/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 0, iter: 759/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 0, iter: 760/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 0, iter: 761/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 0, iter: 762/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 0, iter: 763/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 0, iter: 764/782, Loss 2.80, NLL: 2.80, RegTerm: 0.0, GradNorm: 4.9\n",
      "Clipped gradient with value 7.1 while allowed 7.1\n",
      "Epoch: 0, iter: 765/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 7.1\n",
      "Clipped gradient with value 8.7 while allowed 7.5\n",
      "Epoch: 0, iter: 766/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 8.7\n",
      "Epoch: 0, iter: 767/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 5.9\n",
      "Clipped gradient with value 8.0 while allowed 7.9\n",
      "Epoch: 0, iter: 768/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 0, iter: 769/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 0, iter: 770/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 0, iter: 771/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 0, iter: 772/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 773/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 0, iter: 774/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 0, iter: 775/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 0, iter: 776/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 0, iter: 777/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.7\n",
      "Epoch: 0, iter: 778/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 0, iter: 779/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 0, iter: 780/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 0, iter: 781/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 0/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 1/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 2/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 3/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 4/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 5/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 6/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 7/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 1, iter: 8/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 9/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 10/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 11/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 12/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 13/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 14/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 1, iter: 15/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 1, iter: 16/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 17/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 18/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 19/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 20/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 21/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 22/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 23/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 24/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 25/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 26/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 27/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 28/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 1, iter: 29/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 1, iter: 30/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 1, iter: 31/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 32/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 1, iter: 33/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 34/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.9\n",
      "Epoch: 1, iter: 35/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 36/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 1, iter: 37/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 1, iter: 38/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 39/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 40/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 41/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 42/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 1, iter: 43/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 44/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 1, iter: 45/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 46/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 1, iter: 47/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 48/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 49/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 50/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 51/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 52/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 53/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 54/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 55/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 56/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 57/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 58/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 59/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 60/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 61/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 62/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 63/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 64/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 65/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 66/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 67/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 1, iter: 68/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 69/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 1, iter: 70/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 71/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 72/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 73/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 74/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 75/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 76/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 1, iter: 77/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 78/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 79/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 80/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 8.4\n",
      "Epoch: 1, iter: 81/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 82/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 1, iter: 83/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 84/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 1, iter: 85/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 86/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 87/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 88/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 89/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 90/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.3\n",
      "Clipped gradient with value 8.2 while allowed 8.0\n",
      "Epoch: 1, iter: 91/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 1, iter: 92/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Clipped gradient with value 12.1 while allowed 8.2\n",
      "Epoch: 1, iter: 93/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 12.1\n",
      "Epoch: 1, iter: 94/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.2\n",
      "Clipped gradient with value 10.0 while allowed 8.6\n",
      "Epoch: 1, iter: 95/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 10.0\n",
      "Epoch: 1, iter: 96/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 97/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 1, iter: 98/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 99/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 100/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 101/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 102/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 1, iter: 103/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 1, iter: 104/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 105/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 1, iter: 106/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 107/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 108/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 109/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 110/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 111/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 112/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 113/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 114/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 115/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 116/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 117/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 1, iter: 118/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 119/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 1, iter: 120/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 121/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 122/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 123/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 124/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 125/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 126/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 127/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 128/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 129/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 130/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 131/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 132/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 133/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 134/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 135/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 136/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 137/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 138/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 139/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 140/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 141/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 142/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 143/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 144/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 145/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 146/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 1, iter: 147/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 148/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 149/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 150/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 151/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 152/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 153/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 154/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 155/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 1, iter: 156/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 1, iter: 157/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 158/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 159/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 160/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 161/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 162/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 163/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 164/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 165/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 166/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 167/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 168/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 169/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 170/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 171/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 172/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 173/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 174/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 1, iter: 175/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 1, iter: 176/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 177/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 178/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 179/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 180/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 181/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 182/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 1, iter: 183/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.7\n",
      "Clipped gradient with value 9.9 while allowed 6.5\n",
      "Epoch: 1, iter: 184/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 9.9\n",
      "Epoch: 1, iter: 185/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.4\n",
      "Clipped gradient with value 8.8 while allowed 7.0\n",
      "Epoch: 1, iter: 186/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 8.8\n",
      "Epoch: 1, iter: 187/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 1, iter: 188/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 1, iter: 189/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 1, iter: 190/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 1, iter: 191/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 192/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 193/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 194/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 195/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 196/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 197/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 198/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 199/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 200/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 201/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 202/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 203/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 204/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 205/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 206/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 207/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 208/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 209/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 210/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 211/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 212/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 213/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 214/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 215/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 216/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 217/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 218/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 219/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 220/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 221/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 222/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 223/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 1, iter: 224/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 1, iter: 225/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 226/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 227/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 228/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 229/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 230/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 231/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Clipped gradient with value 8.3 while allowed 8.0\n",
      "Epoch: 1, iter: 232/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 1, iter: 233/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.9\n",
      "Epoch: 1, iter: 234/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 235/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 236/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 237/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.5\n",
      "Clipped gradient with value 8.4 while allowed 8.2\n",
      "Epoch: 1, iter: 238/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 8.4\n",
      "Epoch: 1, iter: 239/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 5.3\n",
      "Clipped gradient with value 11.5 while allowed 8.3\n",
      "Epoch: 1, iter: 240/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 11.5\n",
      "Epoch: 1, iter: 241/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.5\n",
      "Clipped gradient with value 20.8 while allowed 8.6\n",
      "Epoch: 1, iter: 242/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 20.8\n",
      "Clipped gradient with value 10.2 while allowed 9.1\n",
      "Epoch: 1, iter: 243/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 10.2\n",
      "Epoch: 1, iter: 244/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 9.0\n",
      "Epoch: 1, iter: 245/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 6.3\n",
      "Clipped gradient with value 14.3 while allowed 10.2\n",
      "Epoch: 1, iter: 246/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 14.3\n",
      "Epoch: 1, iter: 247/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 248/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 1, iter: 249/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 250/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 1, iter: 251/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 252/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 1, iter: 253/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 1, iter: 254/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 255/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 256/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 257/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 258/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 259/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 260/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 261/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 262/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 263/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 264/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 265/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 1, iter: 266/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 1, iter: 267/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 1, iter: 268/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 269/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 270/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 271/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 272/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 273/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 274/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 275/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 276/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 277/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 278/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 1, iter: 279/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 280/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 281/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 282/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 283/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 284/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 285/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 286/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 287/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 288/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 289/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 290/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 291/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 292/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 293/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 9.3\n",
      "Epoch: 1, iter: 294/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 1, iter: 295/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 296/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 1, iter: 297/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 1, iter: 298/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 1, iter: 299/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 300/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 1, iter: 301/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 14.3 while allowed 9.0\n",
      "Epoch: 1, iter: 302/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 14.3\n",
      "Epoch: 1, iter: 303/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 6.1\n",
      "Clipped gradient with value 13.2 while allowed 9.2\n",
      "Epoch: 1, iter: 304/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 13.2\n",
      "Clipped gradient with value 10.1 while allowed 9.7\n",
      "Epoch: 1, iter: 305/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 10.1\n",
      "Clipped gradient with value 10.5 while allowed 10.3\n",
      "Epoch: 1, iter: 306/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 10.5\n",
      "Clipped gradient with value 11.6 while allowed 10.9\n",
      "Epoch: 1, iter: 307/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 11.6\n",
      "Clipped gradient with value 13.4 while allowed 11.5\n",
      "Epoch: 1, iter: 308/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 13.4\n",
      "Epoch: 1, iter: 309/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 10.6\n",
      "Epoch: 1, iter: 310/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 11.2\n",
      "Clipped gradient with value 13.9 while allowed 13.1\n",
      "Epoch: 1, iter: 311/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 13.9\n",
      "Epoch: 1, iter: 312/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 8.6\n",
      "Clipped gradient with value 19.4 while allowed 14.1\n",
      "Epoch: 1, iter: 313/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 19.4\n",
      "Epoch: 1, iter: 314/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Clipped gradient with value 16.1 while allowed 14.9\n",
      "Epoch: 1, iter: 315/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 16.1\n",
      "Epoch: 1, iter: 316/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 1, iter: 317/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 9.4\n",
      "Epoch: 1, iter: 318/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 1, iter: 319/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 1, iter: 320/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 1, iter: 321/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 322/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 10.3\n",
      "Epoch: 1, iter: 323/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 1, iter: 324/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 1, iter: 325/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 1, iter: 326/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 327/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 328/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 1, iter: 329/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 1, iter: 330/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 1, iter: 331/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 332/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 1, iter: 333/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 334/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 335/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 336/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 1, iter: 337/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 338/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 339/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 340/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 341/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 342/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 343/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 344/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 345/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 346/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 347/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 348/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 349/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 350/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 1, iter: 351/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 1, iter: 352/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 353/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 354/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 355/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 356/782, Loss 2.74, NLL: 2.74, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 357/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 358/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 359/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 360/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 361/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 362/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 1, iter: 363/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 364/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 1, iter: 365/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 366/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 367/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 368/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 369/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 1, iter: 370/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 371/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 372/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 373/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 1, iter: 374/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 1, iter: 375/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 376/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 377/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 1, iter: 378/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 1, iter: 379/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 380/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 1, iter: 381/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 382/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 383/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 384/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 385/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 386/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 387/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 1, iter: 388/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 389/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 390/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 391/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 392/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 393/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 1, iter: 394/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 395/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 396/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 397/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 1, iter: 398/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 399/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 400/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 401/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 402/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 403/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 404/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 1, iter: 405/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 406/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 407/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 408/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 409/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 410/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 1, iter: 411/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 1, iter: 412/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 413/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 1, iter: 414/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 415/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 1, iter: 416/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 417/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 1, iter: 418/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 419/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 420/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 421/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 422/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 423/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 424/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 1, iter: 425/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 426/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 1, iter: 427/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Clipped gradient with value 9.0 while allowed 8.7\n",
      "Epoch: 1, iter: 428/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 9.0\n",
      "Epoch: 1, iter: 429/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 1, iter: 430/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 7.6\n",
      "Clipped gradient with value 9.3 while allowed 9.3\n",
      "Epoch: 1, iter: 431/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 9.3\n",
      "Clipped gradient with value 12.6 while allowed 9.8\n",
      "Epoch: 1, iter: 432/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 12.6\n",
      "Epoch: 1, iter: 433/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 8.2\n",
      "Clipped gradient with value 17.0 while allowed 10.7\n",
      "Epoch: 1, iter: 434/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 17.0\n",
      "Epoch: 1, iter: 435/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 9.1\n",
      "Clipped gradient with value 13.2 while allowed 11.6\n",
      "Epoch: 1, iter: 436/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 13.2\n",
      "Epoch: 1, iter: 437/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 1, iter: 438/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 10.5\n",
      "Epoch: 1, iter: 439/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 1, iter: 440/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 441/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 9.3\n",
      "Epoch: 1, iter: 442/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 443/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 1, iter: 444/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 445/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 446/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 447/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 448/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 449/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 450/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 451/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 452/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 453/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 454/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 455/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 456/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 457/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 458/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 1, iter: 459/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 460/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 1, iter: 461/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 462/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 463/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 464/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 1, iter: 465/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 466/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 9.8\n",
      "Epoch: 1, iter: 467/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 468/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 10.8\n",
      "Epoch: 1, iter: 469/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 1, iter: 470/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 1, iter: 471/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 1, iter: 472/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 473/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 474/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 1, iter: 475/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 476/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 477/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 1, iter: 478/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 479/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 480/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 1, iter: 481/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 482/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 1, iter: 483/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 484/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 485/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 486/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 1, iter: 487/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 488/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 1, iter: 489/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 490/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 491/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 492/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 493/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 1, iter: 494/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 1, iter: 495/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 496/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 9.1\n",
      "Epoch: 1, iter: 497/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 498/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 1, iter: 499/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 500/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 501/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 502/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 1, iter: 503/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 1, iter: 504/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 505/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 1, iter: 506/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 1, iter: 507/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 508/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 509/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.2\n",
      "Clipped gradient with value 12.7 while allowed 10.9\n",
      "Epoch: 1, iter: 510/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 12.7\n",
      "Epoch: 1, iter: 511/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 1, iter: 512/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 1, iter: 513/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 10.1\n",
      "Epoch: 1, iter: 514/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 515/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 9.5\n",
      "Epoch: 1, iter: 516/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.5\n",
      "Clipped gradient with value 16.2 while allowed 12.0\n",
      "Epoch: 1, iter: 517/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 16.2\n",
      "Epoch: 1, iter: 518/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 1, iter: 519/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 520/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 1, iter: 521/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 522/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 523/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 524/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 1, iter: 525/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 10.4\n",
      "Epoch: 1, iter: 526/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 527/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 10.1\n",
      "Epoch: 1, iter: 528/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 529/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 530/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 531/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 532/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 533/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 534/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 535/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 536/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 537/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 1, iter: 538/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 1, iter: 539/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 540/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 1, iter: 541/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 542/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 543/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 1, iter: 544/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 1, iter: 545/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 546/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 1, iter: 547/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 1, iter: 548/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 549/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 550/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 1, iter: 551/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 1, iter: 552/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 553/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 554/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 1, iter: 555/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 556/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 557/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 558/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 559/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 1, iter: 560/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.8\n",
      "Clipped gradient with value 12.8 while allowed 12.2\n",
      "Epoch: 1, iter: 561/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 12.8\n",
      "Epoch: 1, iter: 562/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 563/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 1, iter: 564/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 565/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 1, iter: 566/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 567/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 1, iter: 568/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 569/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 570/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 1, iter: 571/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 1, iter: 572/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 573/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 574/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 575/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 576/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 577/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 578/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 1, iter: 579/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 1, iter: 580/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 581/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 1, iter: 582/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 1, iter: 583/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 584/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 585/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 586/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 587/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 588/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 589/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 590/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 591/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 592/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 593/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 594/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 1, iter: 595/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 596/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 1, iter: 597/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 1, iter: 598/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 599/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 1, iter: 600/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 9.8\n",
      "Clipped gradient with value 15.3 while allowed 11.0\n",
      "Epoch: 1, iter: 601/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 15.3\n",
      "Epoch: 1, iter: 602/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 1, iter: 603/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 1, iter: 604/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 605/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 606/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 607/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 1, iter: 608/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 609/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 1, iter: 610/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 611/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 612/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 1, iter: 613/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 614/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 615/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 616/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 617/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 618/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 1, iter: 619/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 620/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 621/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 622/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 623/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 624/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 1, iter: 625/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 626/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 627/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 628/782, Loss 2.74, NLL: 2.74, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 629/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 630/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 631/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 632/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 1, iter: 633/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 634/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 635/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 636/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 637/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 1, iter: 638/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 1, iter: 639/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 1, iter: 640/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 1, iter: 641/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 1, iter: 642/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 1, iter: 643/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 1, iter: 644/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 645/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 646/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 647/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 1, iter: 648/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 1, iter: 649/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 650/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 651/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 1, iter: 652/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.8\n",
      "Clipped gradient with value 10.3 while allowed 8.7\n",
      "Epoch: 1, iter: 653/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 10.3\n",
      "Epoch: 1, iter: 654/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 655/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 1, iter: 656/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 657/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 658/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 659/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 660/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 661/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 662/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 663/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 1, iter: 664/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Clipped gradient with value 13.5 while allowed 9.3\n",
      "Epoch: 1, iter: 665/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 13.5\n",
      "Epoch: 1, iter: 666/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 667/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 668/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 669/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 670/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 671/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 672/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 673/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 1, iter: 674/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 675/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 676/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 677/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 678/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 679/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 680/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 1, iter: 681/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 682/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.6\n",
      "Clipped gradient with value 11.1 while allowed 9.7\n",
      "Epoch: 1, iter: 683/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 11.1\n",
      "Epoch: 1, iter: 684/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 1, iter: 685/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 686/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 687/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.7\n",
      "Epoch: 1, iter: 688/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 9.9\n",
      "Epoch: 1, iter: 689/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 690/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 1, iter: 691/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 8.9\n",
      "Epoch: 1, iter: 692/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 1, iter: 693/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 9.0\n",
      "Epoch: 1, iter: 694/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 695/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 1, iter: 696/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 697/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 1, iter: 698/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 1, iter: 699/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 700/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 9.1\n",
      "Epoch: 1, iter: 701/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 702/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 1, iter: 703/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 704/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 705/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 706/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 1, iter: 707/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 708/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 709/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 710/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 711/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 712/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 1, iter: 713/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 714/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 1, iter: 715/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 716/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 717/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 1, iter: 718/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 719/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 720/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 721/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 1, iter: 722/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 723/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 724/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 1, iter: 725/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 726/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 1, iter: 727/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 728/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 1, iter: 729/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 1, iter: 730/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 731/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 1, iter: 732/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 733/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 1, iter: 734/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 1, iter: 735/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 1, iter: 736/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 737/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 1, iter: 738/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 1, iter: 739/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 740/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 1, iter: 741/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 742/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.8\n",
      "Clipped gradient with value 13.3 while allowed 8.9\n",
      "Epoch: 1, iter: 743/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 13.3\n",
      "Epoch: 1, iter: 744/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 1, iter: 745/782, Loss 2.38, NLL: 2.38, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 1, iter: 746/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 1, iter: 747/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 1, iter: 748/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 12.6 while allowed 9.1\n",
      "Epoch: 1, iter: 749/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 12.6\n",
      "Epoch: 1, iter: 750/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 1, iter: 751/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 1, iter: 752/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 8.9\n",
      "Epoch: 1, iter: 753/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 1, iter: 754/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 1, iter: 755/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 1, iter: 756/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 1, iter: 757/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 1, iter: 758/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 1, iter: 759/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 1, iter: 760/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 761/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 762/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 1, iter: 763/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 1, iter: 764/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 1, iter: 765/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 1, iter: 766/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 1, iter: 767/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 1, iter: 768/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 1, iter: 769/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 1, iter: 770/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 1, iter: 771/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 1, iter: 772/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 1, iter: 773/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 1, iter: 774/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 1, iter: 775/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 1, iter: 776/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 1, iter: 777/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 1, iter: 778/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 1, iter: 779/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 1, iter: 780/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 1, iter: 781/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 0/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 1/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 2/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 2, iter: 3/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 4/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 2, iter: 5/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 10.9\n",
      "Epoch: 2, iter: 6/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 20.5 while allowed 11.7\n",
      "Epoch: 2, iter: 7/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 20.5\n",
      "Epoch: 2, iter: 8/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.9\n",
      "Clipped gradient with value 14.4 while allowed 12.3\n",
      "Epoch: 2, iter: 9/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 14.4\n",
      "Epoch: 2, iter: 10/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 11/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 10.4\n",
      "Epoch: 2, iter: 12/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 13/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 9.2\n",
      "Epoch: 2, iter: 14/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 15/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 2, iter: 16/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 17/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 8.8\n",
      "Epoch: 2, iter: 18/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 2, iter: 19/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 20/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 21/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 22/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 8.6\n",
      "Epoch: 2, iter: 23/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 24/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 2, iter: 25/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 26/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 27/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 2, iter: 28/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 29/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 2, iter: 30/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 31/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 32/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 33/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 34/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 12.4\n",
      "Epoch: 2, iter: 35/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 2, iter: 36/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 9.6\n",
      "Epoch: 2, iter: 37/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 7.7\n",
      "Epoch: 2, iter: 38/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 9.0\n",
      "Epoch: 2, iter: 39/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 11.9\n",
      "Epoch: 2, iter: 40/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 41/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 10.4\n",
      "Epoch: 2, iter: 42/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 43/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 44/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 45/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 46/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 47/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 48/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 49/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 50/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 51/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 52/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 53/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 2, iter: 54/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 8.7\n",
      "Epoch: 2, iter: 55/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 56/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.7\n",
      "Epoch: 2, iter: 57/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 58/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 2, iter: 59/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 2, iter: 60/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 61/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 62/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 63/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 64/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 65/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 66/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 67/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 68/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 69/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 70/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 71/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 72/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 2, iter: 73/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 2, iter: 74/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 75/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 9.3\n",
      "Epoch: 2, iter: 76/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 77/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 2, iter: 78/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 79/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 80/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 2, iter: 81/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 82/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 2, iter: 83/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 84/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 2, iter: 85/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 86/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 87/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 2, iter: 88/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 2, iter: 89/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 2, iter: 90/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Clipped gradient with value 11.4 while allowed 10.9\n",
      "Epoch: 2, iter: 91/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 11.4\n",
      "Epoch: 2, iter: 92/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 9.5\n",
      "Epoch: 2, iter: 93/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 94/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 2, iter: 95/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 96/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 97/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 98/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 99/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 100/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 101/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 102/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 103/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 104/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 105/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 106/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 107/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 108/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 2, iter: 109/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 110/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 2, iter: 111/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 112/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 113/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 114/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 115/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 116/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 117/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 118/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 119/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 120/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 121/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 122/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 123/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 124/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 125/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 126/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 127/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 128/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 2, iter: 129/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 130/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 131/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 2, iter: 132/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 2, iter: 133/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 134/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 9.4\n",
      "Epoch: 2, iter: 135/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.1\n",
      "Clipped gradient with value 10.3 while allowed 10.0\n",
      "Epoch: 2, iter: 136/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 10.3\n",
      "Epoch: 2, iter: 137/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.0\n",
      "Clipped gradient with value 17.2 while allowed 10.5\n",
      "Epoch: 2, iter: 138/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 17.2\n",
      "Epoch: 2, iter: 139/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.6\n",
      "Clipped gradient with value 19.6 while allowed 10.8\n",
      "Epoch: 2, iter: 140/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 19.6\n",
      "Epoch: 2, iter: 141/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Clipped gradient with value 17.2 while allowed 10.8\n",
      "Epoch: 2, iter: 142/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 17.2\n",
      "Epoch: 2, iter: 143/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.8\n",
      "Clipped gradient with value 11.6 while allowed 11.0\n",
      "Epoch: 2, iter: 144/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 11.6\n",
      "Epoch: 2, iter: 145/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 9.8\n",
      "Epoch: 2, iter: 146/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 10.1\n",
      "Clipped gradient with value 17.2 while allowed 12.4\n",
      "Epoch: 2, iter: 147/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 17.2\n",
      "Epoch: 2, iter: 148/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 5.1\n",
      "Clipped gradient with value 19.0 while allowed 13.2\n",
      "Epoch: 2, iter: 149/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 19.0\n",
      "Epoch: 2, iter: 150/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 151/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 8.4\n",
      "Epoch: 2, iter: 152/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 153/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 154/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 2, iter: 155/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 156/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 157/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 158/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 159/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 160/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 161/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 162/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 163/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 164/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 165/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 166/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 167/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 168/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 169/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 9.2\n",
      "Epoch: 2, iter: 170/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 171/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 172/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 173/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 174/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 175/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 176/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 177/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 178/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 179/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 180/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 181/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 182/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 183/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 184/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 185/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 186/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 187/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 188/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 189/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 190/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 2, iter: 191/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 192/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 2, iter: 193/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 2, iter: 194/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 2, iter: 195/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 196/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 10.4\n",
      "Epoch: 2, iter: 197/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 198/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 199/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 200/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 201/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 202/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 203/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 204/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 205/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 206/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 207/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Clipped gradient with value 10.2 while allowed 8.6\n",
      "Epoch: 2, iter: 208/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 10.2\n",
      "Epoch: 2, iter: 209/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 210/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 211/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 212/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 213/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 214/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 215/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 216/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 217/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 218/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 2, iter: 219/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 220/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 221/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 222/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 223/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 2, iter: 224/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 225/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 2, iter: 226/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 227/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 228/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 229/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 230/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 231/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 232/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 233/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 234/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 2, iter: 235/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 236/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 2, iter: 237/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 238/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 2, iter: 239/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Clipped gradient with value 12.5 while allowed 9.3\n",
      "Epoch: 2, iter: 240/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 12.5\n",
      "Epoch: 2, iter: 241/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 1.7\n",
      "Clipped gradient with value 11.3 while allowed 9.8\n",
      "Epoch: 2, iter: 242/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 11.3\n",
      "Epoch: 2, iter: 243/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 2, iter: 244/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 245/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 2, iter: 246/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 7.9\n",
      "Epoch: 2, iter: 247/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 11.4 while allowed 10.1\n",
      "Epoch: 2, iter: 248/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 11.4\n",
      "Epoch: 2, iter: 249/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 250/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 2, iter: 251/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 252/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 253/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 254/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 255/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 256/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 257/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 258/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 259/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 260/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 8.8\n",
      "Epoch: 2, iter: 261/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 262/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 263/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 264/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 265/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 2, iter: 266/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 267/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 268/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 269/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 270/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 271/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 272/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 273/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 274/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.5\n",
      "Clipped gradient with value 13.3 while allowed 10.3\n",
      "Epoch: 2, iter: 275/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 13.3\n",
      "Epoch: 2, iter: 276/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 277/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 278/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 279/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 280/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Clipped gradient with value 12.1 while allowed 10.9\n",
      "Epoch: 2, iter: 281/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 12.1\n",
      "Epoch: 2, iter: 282/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 2, iter: 283/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 9.1\n",
      "Epoch: 2, iter: 284/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 285/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 2, iter: 286/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 287/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 288/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 289/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 290/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 291/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 292/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 293/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 294/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 295/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 296/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 297/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 298/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 2, iter: 299/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 300/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 2, iter: 301/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 2, iter: 302/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 2, iter: 303/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 2, iter: 304/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 2, iter: 305/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 9.4\n",
      "Epoch: 2, iter: 306/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 307/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 9.1\n",
      "Epoch: 2, iter: 308/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 309/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 10.0\n",
      "Epoch: 2, iter: 310/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 2, iter: 311/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 312/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 9.7\n",
      "Epoch: 2, iter: 313/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 314/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 2, iter: 315/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 316/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 317/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 318/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 319/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 320/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 321/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 322/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 323/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 324/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 325/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 326/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 327/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 328/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 329/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 330/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 331/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 332/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 333/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 2, iter: 334/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 335/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 2, iter: 336/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 2, iter: 337/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 338/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 339/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 340/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 2, iter: 341/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 342/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 343/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 344/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 345/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 346/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 347/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 348/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 349/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 2, iter: 350/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 351/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 352/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 353/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 2, iter: 354/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 355/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 356/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 2, iter: 357/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 2, iter: 358/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 2, iter: 359/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 9.0\n",
      "Epoch: 2, iter: 360/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 361/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 362/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 363/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 364/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 365/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 366/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 2, iter: 367/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 368/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 369/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 370/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 371/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 372/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 2, iter: 373/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 374/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 375/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 376/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 377/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 378/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 2, iter: 379/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 380/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 381/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 382/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 383/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 2, iter: 384/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 385/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 386/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 387/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 388/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 389/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 390/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 391/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 392/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 393/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 394/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 2, iter: 395/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 396/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 2, iter: 397/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 398/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 399/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 400/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 401/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 402/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 403/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 404/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 2, iter: 405/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 2, iter: 406/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 2, iter: 407/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 408/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 409/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 2, iter: 410/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 411/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 412/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 413/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 414/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 415/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 2, iter: 416/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 2, iter: 417/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 418/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 2, iter: 419/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 420/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 2, iter: 421/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.1\n",
      "Clipped gradient with value 15.3 while allowed 9.4\n",
      "Epoch: 2, iter: 422/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 15.3\n",
      "Epoch: 2, iter: 423/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.4\n",
      "Clipped gradient with value 10.9 while allowed 9.8\n",
      "Epoch: 2, iter: 424/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 10.9\n",
      "Epoch: 2, iter: 425/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 9.0\n",
      "Epoch: 2, iter: 426/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 427/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 428/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 429/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 2, iter: 430/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 431/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 432/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 433/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 434/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 435/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 436/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 437/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 438/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 439/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 440/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 441/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 442/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 443/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 444/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 445/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 446/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 447/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 448/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 449/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 450/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 451/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 452/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 453/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 454/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 2, iter: 455/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 456/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 457/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 458/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 459/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 460/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 461/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 462/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 463/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 464/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 465/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 466/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 467/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 2, iter: 468/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 2, iter: 469/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 470/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 471/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 472/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 2, iter: 473/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 2, iter: 474/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 2, iter: 475/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 476/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 477/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 478/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 479/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 480/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 481/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 2, iter: 482/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 483/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 2, iter: 484/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 485/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 486/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 2, iter: 487/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 488/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 489/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 490/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 2, iter: 491/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 492/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 2, iter: 493/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 494/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.5\n",
      "Clipped gradient with value 10.6 while allowed 8.4\n",
      "Epoch: 2, iter: 495/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 10.6\n",
      "Epoch: 2, iter: 496/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 497/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 8.9\n",
      "Epoch: 2, iter: 498/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 499/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 500/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 501/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 2, iter: 502/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 503/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 504/782, Loss 2.38, NLL: 2.38, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 505/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 506/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 507/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 508/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 509/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 510/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 511/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 512/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 513/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 514/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 515/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 2, iter: 516/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.8\n",
      "Clipped gradient with value 11.0 while allowed 10.2\n",
      "Epoch: 2, iter: 517/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 11.0\n",
      "Epoch: 2, iter: 518/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 519/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 9.4\n",
      "Epoch: 2, iter: 520/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 521/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 9.1\n",
      "Epoch: 2, iter: 522/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 523/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 7.9\n",
      "Epoch: 2, iter: 524/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 525/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 2, iter: 526/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 527/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 528/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 529/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 530/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 531/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 532/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 533/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 534/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 535/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 536/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 537/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 538/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 539/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 540/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 541/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 542/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 543/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 544/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 545/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 546/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 2, iter: 547/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 2, iter: 548/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 549/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 550/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 551/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 552/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 553/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 554/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 555/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 556/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 557/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 558/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 559/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 560/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 561/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 562/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 563/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 2, iter: 564/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 565/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 566/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 567/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 568/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 569/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 570/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 571/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 572/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 573/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 574/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 575/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 576/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 7.4 while allowed 7.1\n",
      "Epoch: 2, iter: 577/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.4\n",
      "Clipped gradient with value 11.2 while allowed 7.5\n",
      "Epoch: 2, iter: 578/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 11.2\n",
      "Epoch: 2, iter: 579/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 580/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 2, iter: 581/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 582/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 583/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 584/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 2, iter: 585/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 586/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 587/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 588/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 589/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 590/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 591/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 592/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 593/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 594/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 595/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 596/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 597/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 598/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 599/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 600/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 2, iter: 601/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 602/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 603/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 604/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.9\n",
      "Clipped gradient with value 8.3 while allowed 7.9\n",
      "Epoch: 2, iter: 605/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 2, iter: 606/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 607/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 2, iter: 608/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 2, iter: 609/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 2, iter: 610/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 611/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 2, iter: 612/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 613/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 614/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 615/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 616/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 2, iter: 617/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 2, iter: 618/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 2, iter: 619/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 2, iter: 620/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 8.8\n",
      "Epoch: 2, iter: 621/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 622/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 623/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 2, iter: 624/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 2, iter: 625/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 12.1 while allowed 10.3\n",
      "Epoch: 2, iter: 626/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 12.1\n",
      "Epoch: 2, iter: 627/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Clipped gradient with value 11.9 while allowed 10.6\n",
      "Epoch: 2, iter: 628/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 11.9\n",
      "Epoch: 2, iter: 629/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 630/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 10.3\n",
      "Epoch: 2, iter: 631/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 632/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 633/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 634/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 635/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 636/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 637/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 638/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 639/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 640/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 641/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 642/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 643/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 644/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 645/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 646/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 2, iter: 647/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 648/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 649/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 650/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 651/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 652/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 2, iter: 653/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 2, iter: 654/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 2, iter: 655/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 656/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 657/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 658/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 659/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 9.9\n",
      "Epoch: 2, iter: 660/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 2, iter: 661/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 2, iter: 662/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 2, iter: 663/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 664/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 2, iter: 665/782, Loss 2.39, NLL: 2.39, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 666/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 2, iter: 667/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 2, iter: 668/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 2, iter: 669/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 670/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 2, iter: 671/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 2, iter: 672/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 673/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 674/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 675/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 676/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 2, iter: 677/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 678/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 679/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 2, iter: 680/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 681/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 2, iter: 682/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 683/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 684/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 685/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 2, iter: 686/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 687/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 688/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 689/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 690/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 691/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 692/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 2, iter: 693/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 2, iter: 694/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 695/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 696/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 2, iter: 697/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 698/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 699/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 700/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 701/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 2, iter: 702/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 703/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 704/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 2, iter: 705/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 706/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 707/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 2, iter: 708/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 709/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 710/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 2, iter: 711/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 9.6 while allowed 8.6\n",
      "Epoch: 2, iter: 712/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 9.6\n",
      "Epoch: 2, iter: 713/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 714/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 715/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.0\n",
      "Clipped gradient with value 10.4 while allowed 8.7\n",
      "Epoch: 2, iter: 716/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 10.4\n",
      "Clipped gradient with value 9.7 while allowed 9.1\n",
      "Epoch: 2, iter: 717/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 9.7\n",
      "Epoch: 2, iter: 718/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 2, iter: 719/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 2, iter: 720/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 2, iter: 721/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 9.8\n",
      "Epoch: 2, iter: 722/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 2, iter: 723/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 2, iter: 724/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 725/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 2, iter: 726/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 727/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 2, iter: 728/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 729/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 2, iter: 730/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 2, iter: 731/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 2, iter: 732/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 8.4\n",
      "Epoch: 2, iter: 733/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 2, iter: 734/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 2, iter: 735/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 2, iter: 736/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 737/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 738/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 739/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 740/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 2, iter: 741/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 2, iter: 742/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 2, iter: 743/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 744/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 745/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 746/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 2, iter: 747/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 2, iter: 748/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 749/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 2, iter: 750/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 2, iter: 751/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 2, iter: 752/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 753/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 754/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 2, iter: 755/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 2, iter: 756/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 757/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 2, iter: 758/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 2, iter: 759/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 2, iter: 760/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 2, iter: 761/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 2, iter: 762/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 2, iter: 763/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 764/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 2, iter: 765/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 2, iter: 766/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 2, iter: 767/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 2, iter: 768/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 2, iter: 769/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 770/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 2, iter: 771/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 2, iter: 772/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 2, iter: 773/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 2, iter: 774/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 2, iter: 775/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 2, iter: 776/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 777/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 2, iter: 778/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 2, iter: 779/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 2, iter: 780/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 2, iter: 781/782, Loss 2.79, NLL: 2.79, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 0/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 1/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 3, iter: 2/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 3/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 3, iter: 4/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 5/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 6/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 7/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 8/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 9/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 10/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 11/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 12/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 13/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 14/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 15/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 16/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 17/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 18/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 19/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 20/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 21/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 22/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 23/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 24/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 25/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 3, iter: 26/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 3, iter: 27/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 28/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 29/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 30/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 31/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 32/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 33/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 34/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 35/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 36/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 37/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 38/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 39/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 40/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 41/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 42/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 43/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 44/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 45/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 46/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 47/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 48/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 49/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 3, iter: 50/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 51/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 52/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 53/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 54/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 55/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 56/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 57/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 58/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 59/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 60/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 61/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 62/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 63/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 64/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 65/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 66/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 67/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 68/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 69/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.7\n",
      "Clipped gradient with value 8.2 while allowed 6.3\n",
      "Epoch: 3, iter: 70/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 3, iter: 71/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 72/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 73/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 74/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 75/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 76/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 77/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 3, iter: 78/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 79/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 80/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 81/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 82/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 83/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 84/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 85/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 86/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 87/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 88/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Clipped gradient with value 6.7 while allowed 6.3\n",
      "Epoch: 3, iter: 89/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 3, iter: 90/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 91/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 3, iter: 92/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 93/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 94/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 95/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 3, iter: 96/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Clipped gradient with value 9.5 while allowed 7.0\n",
      "Epoch: 3, iter: 97/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 9.5\n",
      "Epoch: 3, iter: 98/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 3, iter: 99/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.8\n",
      "Clipped gradient with value 8.7 while allowed 7.7\n",
      "Epoch: 3, iter: 100/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 8.7\n",
      "Clipped gradient with value 12.2 while allowed 8.2\n",
      "Epoch: 3, iter: 101/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 12.2\n",
      "Epoch: 3, iter: 102/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.5\n",
      "Clipped gradient with value 9.4 while allowed 8.6\n",
      "Epoch: 3, iter: 103/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 9.4\n",
      "Epoch: 3, iter: 104/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 105/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.4\n",
      "Clipped gradient with value 9.5 while allowed 9.2\n",
      "Epoch: 3, iter: 106/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 9.5\n",
      "Epoch: 3, iter: 107/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.3\n",
      "Clipped gradient with value 11.9 while allowed 9.7\n",
      "Epoch: 3, iter: 108/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 11.9\n",
      "Epoch: 3, iter: 109/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 110/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 111/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 112/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 3, iter: 113/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 3, iter: 114/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 3, iter: 115/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 3, iter: 116/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 117/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 118/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 119/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 120/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 121/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 122/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 123/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 124/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 125/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 7.7\n",
      "Epoch: 3, iter: 126/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 127/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 3, iter: 128/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 129/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 130/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 131/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 132/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 3, iter: 133/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 134/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 135/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 136/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 137/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 138/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 139/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 140/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 3, iter: 141/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 142/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 143/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 3, iter: 144/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 145/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 146/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 147/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 148/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 149/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 3, iter: 150/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 151/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 152/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 153/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 3, iter: 154/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 155/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 156/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 157/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 158/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Clipped gradient with value 8.1 while allowed 7.7\n",
      "Epoch: 3, iter: 159/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 3, iter: 160/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 3, iter: 161/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 3, iter: 162/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 163/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 164/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 165/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 166/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 167/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 168/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 169/782, Loss 2.39, NLL: 2.39, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 170/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 171/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 172/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 173/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 174/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 3, iter: 175/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 176/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 177/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 178/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 3, iter: 179/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 180/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 3, iter: 181/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 182/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 3, iter: 183/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 3, iter: 184/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.8\n",
      "Clipped gradient with value 9.4 while allowed 8.4\n",
      "Epoch: 3, iter: 185/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 9.4\n",
      "Epoch: 3, iter: 186/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 187/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 3, iter: 188/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 189/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 190/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 191/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 192/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 193/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 194/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 195/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 196/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 197/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 198/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 199/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 200/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 201/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 202/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 203/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 204/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 205/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 206/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 3, iter: 207/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 208/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 3, iter: 209/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 210/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 211/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 212/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 3, iter: 213/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 214/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 3, iter: 215/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 216/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 217/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 218/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 219/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 220/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 221/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 222/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 223/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 224/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 225/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 226/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 227/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 228/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 229/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 230/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 231/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 232/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 233/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 234/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 235/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 236/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 237/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 238/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 239/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 240/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 241/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 242/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 243/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.0\n",
      "Clipped gradient with value 8.3 while allowed 5.6\n",
      "Epoch: 3, iter: 244/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 3, iter: 245/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 246/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 247/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 248/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Clipped gradient with value 10.8 while allowed 6.2\n",
      "Epoch: 3, iter: 249/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 10.8\n",
      "Epoch: 3, iter: 250/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Clipped gradient with value 13.7 while allowed 6.5\n",
      "Epoch: 3, iter: 251/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 13.7\n",
      "Clipped gradient with value 10.9 while allowed 6.8\n",
      "Epoch: 3, iter: 252/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 10.9\n",
      "Epoch: 3, iter: 253/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Clipped gradient with value 10.1 while allowed 7.2\n",
      "Epoch: 3, iter: 254/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 10.1\n",
      "Epoch: 3, iter: 255/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 256/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 257/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 258/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 3, iter: 259/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 260/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 3, iter: 261/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 3, iter: 262/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 263/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 3, iter: 264/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 265/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 3, iter: 266/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 267/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 3, iter: 268/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 269/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 3, iter: 270/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 8.4\n",
      "Epoch: 3, iter: 271/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 272/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 3, iter: 273/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 3, iter: 274/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 275/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 3, iter: 276/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 277/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 3, iter: 278/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 3, iter: 279/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 280/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 3, iter: 281/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 282/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 283/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 3, iter: 284/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 285/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 286/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 287/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 288/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 289/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 290/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 3, iter: 291/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 292/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 3, iter: 293/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 294/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 295/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 296/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 297/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 3, iter: 298/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 299/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 3, iter: 300/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 301/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 302/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 303/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 304/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 305/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 3, iter: 306/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 307/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 308/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 309/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 310/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 311/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 312/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 313/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 314/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 315/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 316/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 317/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 318/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 319/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 320/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 321/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 322/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 323/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 324/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 325/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 326/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 327/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 328/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 3, iter: 329/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 330/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 331/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 332/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 333/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 334/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 335/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 336/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 337/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 338/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 339/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 340/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 341/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 342/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 343/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 344/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 345/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 346/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 347/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 348/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 349/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 350/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.3\n",
      "Clipped gradient with value 12.4 while allowed 6.4\n",
      "Epoch: 3, iter: 351/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 12.4\n",
      "Epoch: 3, iter: 352/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 353/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 5.7\n",
      "Clipped gradient with value 7.4 while allowed 6.8\n",
      "Epoch: 3, iter: 354/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 7.4\n",
      "Clipped gradient with value 8.9 while allowed 7.2\n",
      "Epoch: 3, iter: 355/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 8.9\n",
      "Epoch: 3, iter: 356/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 3, iter: 357/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 3, iter: 358/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 3, iter: 359/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 360/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 361/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 362/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 363/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 3, iter: 364/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 3, iter: 365/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 366/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 367/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 368/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 3, iter: 369/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 370/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 371/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 3, iter: 372/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 3, iter: 373/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 3, iter: 374/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 3, iter: 375/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.0\n",
      "Clipped gradient with value 10.1 while allowed 9.3\n",
      "Epoch: 3, iter: 376/782, Loss 2.38, NLL: 2.38, RegTerm: 0.0, GradNorm: 10.1\n",
      "Epoch: 3, iter: 377/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 3, iter: 378/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 3, iter: 379/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 3, iter: 380/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 381/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 3, iter: 382/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 3, iter: 383/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 384/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 9.8\n",
      "Epoch: 3, iter: 385/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 386/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 3, iter: 387/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 388/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 3, iter: 389/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 390/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 391/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 3, iter: 392/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 393/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 3, iter: 394/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 395/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 396/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 397/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 398/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 3, iter: 399/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 400/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 401/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 3, iter: 402/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 403/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 404/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 405/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 406/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 407/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 408/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 409/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 410/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 3, iter: 411/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 412/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 413/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 414/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 415/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 416/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 417/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 418/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 3, iter: 419/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 420/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 421/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 422/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 423/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 424/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 425/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 426/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 427/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 428/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 429/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 430/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 3, iter: 431/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 432/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 433/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 434/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 435/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 436/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 437/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 438/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 439/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 440/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 441/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 442/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 443/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 444/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 445/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 446/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 3, iter: 447/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 448/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.5\n",
      "Clipped gradient with value 6.9 while allowed 6.9\n",
      "Epoch: 3, iter: 449/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 3, iter: 450/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 451/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 3, iter: 452/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 453/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 3, iter: 454/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 3, iter: 455/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 456/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 457/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 458/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 459/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 460/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 461/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 462/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 3, iter: 463/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 464/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 3, iter: 465/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Clipped gradient with value 10.4 while allowed 7.7\n",
      "Epoch: 3, iter: 466/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 10.4\n",
      "Epoch: 3, iter: 467/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 468/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 469/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 3, iter: 470/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 471/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 3, iter: 472/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 473/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 3, iter: 474/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 3, iter: 475/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.7\n",
      "Clipped gradient with value 9.8 while allowed 8.8\n",
      "Epoch: 3, iter: 476/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 9.8\n",
      "Epoch: 3, iter: 477/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 478/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 9.2\n",
      "Epoch: 3, iter: 479/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 480/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 3, iter: 481/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 482/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 8.5\n",
      "Epoch: 3, iter: 483/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 484/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 485/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 486/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 487/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 488/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 489/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 490/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 491/782, Loss 2.39, NLL: 2.39, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 492/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 493/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 494/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 495/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 496/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 497/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 498/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 499/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 3, iter: 500/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 501/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 3, iter: 502/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 503/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 504/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 505/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 506/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 507/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 508/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 509/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 510/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 511/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 3, iter: 512/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 513/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 514/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 515/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 516/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 517/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 518/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 519/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 520/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 521/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 522/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 523/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 524/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 525/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 526/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 527/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 3, iter: 528/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 529/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 530/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 531/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 532/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 3, iter: 533/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 534/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 3, iter: 535/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 536/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 537/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 538/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 539/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 3, iter: 540/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 3, iter: 541/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.9\n",
      "Clipped gradient with value 8.0 while allowed 7.7\n",
      "Epoch: 3, iter: 542/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 3, iter: 543/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Clipped gradient with value 8.6 while allowed 8.1\n",
      "Epoch: 3, iter: 544/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 8.6\n",
      "Epoch: 3, iter: 545/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 3, iter: 546/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 547/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 548/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 549/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 550/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 551/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 552/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 553/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 554/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 555/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 556/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 557/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 558/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 559/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 560/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 561/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 562/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 563/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 564/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 3, iter: 565/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 566/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 567/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 568/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 569/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 570/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 571/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 572/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 573/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 574/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 3, iter: 575/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 576/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 3, iter: 577/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 578/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 579/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 580/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 581/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 582/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 583/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 584/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 585/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 586/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 587/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 588/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 3, iter: 589/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 590/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 591/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 592/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 593/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 594/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 3, iter: 595/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 596/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 3, iter: 597/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 598/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 3, iter: 599/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 600/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 601/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 3, iter: 602/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 603/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 604/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 605/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 3, iter: 606/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 607/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 3, iter: 608/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 609/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 610/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 611/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 3, iter: 612/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 613/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 614/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 615/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 616/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 617/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 3, iter: 618/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 619/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 620/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 621/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 622/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 623/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 624/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 3, iter: 625/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.1\n",
      "Clipped gradient with value 11.7 while allowed 6.6\n",
      "Epoch: 3, iter: 626/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 11.7\n",
      "Clipped gradient with value 12.1 while allowed 6.8\n",
      "Epoch: 3, iter: 627/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 12.1\n",
      "Epoch: 3, iter: 628/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.2\n",
      "Clipped gradient with value 11.0 while allowed 7.2\n",
      "Epoch: 3, iter: 629/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 11.0\n",
      "Epoch: 3, iter: 630/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.1\n",
      "Clipped gradient with value 10.7 while allowed 7.7\n",
      "Epoch: 3, iter: 631/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 10.7\n",
      "Clipped gradient with value 11.6 while allowed 8.1\n",
      "Epoch: 3, iter: 632/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 11.6\n",
      "Epoch: 3, iter: 633/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 3, iter: 634/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 635/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 636/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 637/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 3, iter: 638/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 639/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 640/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 641/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 642/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 643/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 644/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 3, iter: 645/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 646/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 3, iter: 647/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 648/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 649/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 3, iter: 650/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 651/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 652/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 653/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 654/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 655/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 656/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 657/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 658/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 659/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 660/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 661/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 662/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 663/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 664/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 665/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 666/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 667/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 668/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 669/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 670/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 3, iter: 671/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 672/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 673/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 674/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 675/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 676/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 677/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 678/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 679/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 680/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 681/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 682/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 3, iter: 683/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 684/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 3, iter: 685/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 686/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 3, iter: 687/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 688/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 689/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 690/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 691/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 3, iter: 692/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.4\n",
      "Clipped gradient with value 7.0 while allowed 6.3\n",
      "Epoch: 3, iter: 693/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 3, iter: 694/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Clipped gradient with value 8.8 while allowed 6.3\n",
      "Epoch: 3, iter: 695/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 8.8\n",
      "Epoch: 3, iter: 696/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.2\n",
      "Clipped gradient with value 7.9 while allowed 6.5\n",
      "Epoch: 3, iter: 697/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.9\n",
      "Epoch: 3, iter: 698/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 699/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 700/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 701/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 702/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 3, iter: 703/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 704/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 3, iter: 705/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 706/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 707/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 3, iter: 708/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 709/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 710/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 711/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 3, iter: 712/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 713/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 714/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 715/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 3, iter: 716/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 717/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 3, iter: 718/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 3, iter: 719/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 720/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 721/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 722/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 723/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 724/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 3, iter: 725/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 726/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 727/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 728/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 3, iter: 729/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 730/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 731/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 3, iter: 732/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 733/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 734/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 735/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 736/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 737/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 738/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 739/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 740/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 3, iter: 741/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 742/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 3, iter: 743/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 3, iter: 744/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 3, iter: 745/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 3, iter: 746/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 747/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 748/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 3, iter: 749/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 3, iter: 750/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 3, iter: 751/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 752/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 753/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 754/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 3, iter: 755/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 756/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 3, iter: 757/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 3, iter: 758/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 3, iter: 759/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 3, iter: 760/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 3, iter: 761/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 762/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 3, iter: 763/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 3, iter: 764/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 765/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 766/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 3, iter: 767/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 3, iter: 768/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 3, iter: 769/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 3, iter: 770/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 3, iter: 771/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 3, iter: 772/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 3, iter: 773/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 3, iter: 774/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 3, iter: 775/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 776/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 3, iter: 777/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 3, iter: 778/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 3, iter: 779/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 3, iter: 780/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 3, iter: 781/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.6\n",
      "Clipped gradient with value 7.0 while allowed 6.8\n",
      "Epoch: 4, iter: 0/782, Loss 2.37, NLL: 2.37, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 4, iter: 1/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 4, iter: 2/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 4, iter: 3/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 4/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 5/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 6/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 4, iter: 7/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 8/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 9/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 10/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 11/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 12/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 13/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 14/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 15/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 16/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 17/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 4, iter: 18/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 19/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 4, iter: 20/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 21/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 22/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 23/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 4, iter: 24/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 25/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 4, iter: 26/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 27/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 28/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 29/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 30/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 31/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 32/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 33/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 4, iter: 34/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 35/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 36/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 37/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 4, iter: 38/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 39/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 40/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 41/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 42/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 43/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 44/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 45/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 46/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 47/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 48/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 49/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 50/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 51/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 52/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 53/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 54/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 55/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 56/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 57/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 4, iter: 58/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 59/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 60/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 61/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 62/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 4, iter: 63/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 4, iter: 64/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 65/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 4, iter: 66/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 67/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 4, iter: 68/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 69/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 4, iter: 70/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 8.4 while allowed 6.5\n",
      "Epoch: 4, iter: 71/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 8.4\n",
      "Epoch: 4, iter: 72/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.6\n",
      "Clipped gradient with value 7.8 while allowed 6.8\n",
      "Epoch: 4, iter: 73/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 4, iter: 74/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 75/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 76/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 77/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 4, iter: 78/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 79/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 80/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 4, iter: 81/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 82/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 83/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 84/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 85/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 86/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 87/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 88/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 89/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 90/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 91/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 92/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 93/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 4, iter: 94/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 95/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 4, iter: 96/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 97/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 98/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 4, iter: 99/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 4, iter: 100/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 4, iter: 101/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 4, iter: 102/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 8.8\n",
      "Clipped gradient with value 13.6 while allowed 9.5\n",
      "Epoch: 4, iter: 103/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 13.6\n",
      "Epoch: 4, iter: 104/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 4, iter: 105/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 106/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 4, iter: 107/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 108/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 4, iter: 109/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 110/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 111/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 112/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 113/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 114/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 115/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 116/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 117/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 118/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 4, iter: 119/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 120/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 121/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 122/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 4, iter: 123/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 124/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 125/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 126/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 127/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 4, iter: 128/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 4, iter: 129/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 130/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 4, iter: 131/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 132/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 133/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 134/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 4, iter: 135/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 136/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 137/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 138/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 139/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 140/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 141/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 142/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 143/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 144/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 145/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 4, iter: 146/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 147/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 148/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 149/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 150/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 151/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 152/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 153/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 154/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 155/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 156/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 157/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 158/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 159/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 160/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 161/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 162/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 163/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 164/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 165/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.5\n",
      "Epoch: 4, iter: 166/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 167/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 168/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 169/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 170/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 171/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 172/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 173/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 174/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 175/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 176/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 4, iter: 177/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 178/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 179/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 180/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 181/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 182/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 183/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 4, iter: 184/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.2\n",
      "Clipped gradient with value 6.9 while allowed 6.6\n",
      "Epoch: 4, iter: 185/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 4, iter: 186/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 187/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 4, iter: 188/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 189/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 190/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 191/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 4, iter: 192/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 193/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 4, iter: 194/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 195/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 196/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 197/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 4, iter: 198/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 199/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 4, iter: 200/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Clipped gradient with value 8.1 while allowed 7.3\n",
      "Epoch: 4, iter: 201/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 4, iter: 202/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 203/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 204/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 205/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 206/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 207/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 4, iter: 208/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 209/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 210/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 211/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 212/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 4, iter: 213/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 214/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 215/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 4, iter: 216/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 217/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 9.5 while allowed 8.1\n",
      "Epoch: 4, iter: 218/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 9.5\n",
      "Epoch: 4, iter: 219/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 4, iter: 220/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 221/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 222/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 223/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 224/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 225/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 4, iter: 226/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 227/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 228/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 229/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 230/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 231/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 4, iter: 232/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 233/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 234/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.4\n",
      "Clipped gradient with value 10.0 while allowed 8.7\n",
      "Epoch: 4, iter: 235/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 10.0\n",
      "Epoch: 4, iter: 236/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.0\n",
      "Clipped gradient with value 10.5 while allowed 9.0\n",
      "Epoch: 4, iter: 237/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 10.5\n",
      "Epoch: 4, iter: 238/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 239/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 240/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 241/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 4, iter: 242/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 243/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 244/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 245/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 246/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 247/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 248/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 249/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 250/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 251/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 252/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 253/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 254/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 255/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 256/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 257/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 258/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 259/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 260/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 261/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 262/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 263/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 264/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 265/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 266/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 267/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 268/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 269/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 270/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 271/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 272/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 273/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 274/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 275/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 276/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 277/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 278/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 279/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 280/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 281/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 282/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 283/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 284/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 285/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 4, iter: 286/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 287/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 4, iter: 288/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.9\n",
      "Clipped gradient with value 7.3 while allowed 6.1\n",
      "Epoch: 4, iter: 289/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 4, iter: 290/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Clipped gradient with value 7.2 while allowed 6.3\n",
      "Epoch: 4, iter: 291/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 7.2\n",
      "Clipped gradient with value 6.7 while allowed 6.5\n",
      "Epoch: 4, iter: 292/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 4, iter: 293/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.5\n",
      "Clipped gradient with value 7.2 while allowed 7.2\n",
      "Epoch: 4, iter: 294/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 4, iter: 295/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.4\n",
      "Clipped gradient with value 7.9 while allowed 7.6\n",
      "Epoch: 4, iter: 296/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 7.9\n",
      "Epoch: 4, iter: 297/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 4, iter: 298/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 4, iter: 299/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 300/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 4, iter: 301/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 302/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 4, iter: 303/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 304/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 305/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 306/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 307/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 4, iter: 308/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 309/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 310/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 311/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 312/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 313/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 314/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 315/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 316/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 317/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 318/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 319/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 4, iter: 320/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 321/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 4, iter: 322/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 323/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 324/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 325/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 326/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 327/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 328/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 329/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 330/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 331/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 332/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 333/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 334/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 335/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 336/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 337/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 4, iter: 338/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 339/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 340/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 341/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 342/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 343/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 344/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 345/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 4, iter: 346/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 4, iter: 347/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 348/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 349/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 350/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 351/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 352/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 353/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 354/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 4, iter: 355/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 356/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 357/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 358/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 359/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 360/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 361/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 362/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 363/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 364/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 365/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 4, iter: 366/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 367/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 368/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 369/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 4, iter: 370/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 371/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 372/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 4, iter: 373/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.2\n",
      "Clipped gradient with value 8.1 while allowed 6.3\n",
      "Epoch: 4, iter: 374/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 4, iter: 375/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 376/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 4, iter: 377/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 378/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 379/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 4, iter: 380/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 381/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 4, iter: 382/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 383/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 384/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 385/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 386/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 387/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 388/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 4, iter: 389/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 390/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 391/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 392/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 393/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 394/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 395/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 396/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 397/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 398/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 399/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 400/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 401/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 402/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 403/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 404/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 4, iter: 405/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.7\n",
      "Clipped gradient with value 9.0 while allowed 7.0\n",
      "Epoch: 4, iter: 406/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 9.0\n",
      "Epoch: 4, iter: 407/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Clipped gradient with value 8.5 while allowed 7.4\n",
      "Epoch: 4, iter: 408/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 8.5\n",
      "Epoch: 4, iter: 409/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 410/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 4, iter: 411/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 412/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 413/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 414/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 4, iter: 415/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 416/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 417/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 418/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 419/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 420/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 421/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 422/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 423/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 424/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 425/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 426/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 427/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 428/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 429/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 430/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 431/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 432/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 4, iter: 433/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 4, iter: 434/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 435/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Clipped gradient with value 7.3 while allowed 7.1\n",
      "Epoch: 4, iter: 436/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 4, iter: 437/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 438/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 4, iter: 439/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 440/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 441/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 442/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 443/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 444/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 4, iter: 445/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 446/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 447/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 448/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 4, iter: 449/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 450/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 4, iter: 451/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 452/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 4, iter: 453/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 4, iter: 454/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 4, iter: 455/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 4, iter: 456/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 4, iter: 457/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 8.5\n",
      "Epoch: 4, iter: 458/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 4, iter: 459/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.9\n",
      "Epoch: 4, iter: 460/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 4, iter: 461/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 462/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 463/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 464/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 465/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 466/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 467/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 468/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 469/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 4, iter: 470/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 471/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 4, iter: 472/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 473/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 474/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 475/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 476/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 477/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 478/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 8.6\n",
      "Epoch: 4, iter: 479/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 480/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 4, iter: 481/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 482/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 483/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 4, iter: 484/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 485/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 486/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 487/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 4, iter: 488/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 4, iter: 489/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 490/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 491/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 492/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 493/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 494/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 495/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 496/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 497/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 498/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 4, iter: 499/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 4, iter: 500/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 501/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 502/782, Loss 2.75, NLL: 2.75, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 4, iter: 503/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 504/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 505/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 506/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 507/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 508/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 509/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 510/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 511/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 512/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 513/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 514/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 515/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Clipped gradient with value 8.9 while allowed 7.0\n",
      "Epoch: 4, iter: 516/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 8.9\n",
      "Epoch: 4, iter: 517/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 4, iter: 518/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 4, iter: 519/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 4, iter: 520/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 521/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 522/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 523/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 524/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 525/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 4, iter: 526/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 527/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 528/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 529/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 530/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 531/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 532/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 533/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 534/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 535/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 536/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 537/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 538/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 4, iter: 539/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 540/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 541/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 542/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 543/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 544/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 545/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 546/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 547/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 548/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 549/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 550/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 551/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 552/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 553/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 554/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 555/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 4, iter: 556/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 557/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 558/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 559/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 560/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 4, iter: 561/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 562/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 4, iter: 563/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 4, iter: 564/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 4, iter: 565/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 4, iter: 566/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 567/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 568/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 4, iter: 569/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 570/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 4, iter: 571/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 572/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 573/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 574/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 575/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 4, iter: 576/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 577/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 4, iter: 578/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 579/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 4, iter: 580/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 581/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 582/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 583/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 584/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 4, iter: 585/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 586/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 4, iter: 587/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 588/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 4, iter: 589/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 590/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 591/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 592/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 4, iter: 593/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 10.5 while allowed 8.3\n",
      "Epoch: 4, iter: 594/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 10.5\n",
      "Epoch: 4, iter: 595/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 596/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 4, iter: 597/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 4, iter: 598/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 4, iter: 599/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 9.2\n",
      "Epoch: 4, iter: 600/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 4, iter: 601/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 9.4\n",
      "Epoch: 4, iter: 602/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 4, iter: 603/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 8.4\n",
      "Epoch: 4, iter: 604/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 605/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 606/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 607/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 608/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 609/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 610/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 611/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 612/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 613/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 614/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 615/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 616/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 617/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 618/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 619/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 620/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 621/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 622/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 623/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 624/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 625/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 4, iter: 626/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 627/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 4, iter: 628/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 629/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 8.1\n",
      "Epoch: 4, iter: 630/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 631/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 4, iter: 632/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 633/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 634/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 635/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 636/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 637/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 638/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 639/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 640/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 641/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 642/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 643/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 644/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 4, iter: 645/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 646/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 4, iter: 647/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 648/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 649/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 650/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 651/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 4, iter: 652/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 653/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 4, iter: 654/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 655/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 656/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 657/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 4, iter: 658/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 659/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 660/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 661/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 662/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 663/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 4, iter: 664/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 665/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 666/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 667/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 668/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 669/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 670/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 4, iter: 671/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 4, iter: 672/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 4, iter: 673/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 674/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 4, iter: 675/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 676/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 4, iter: 677/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 678/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 4, iter: 679/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 680/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 681/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 4, iter: 682/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 4, iter: 683/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 684/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 685/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 4, iter: 686/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 687/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 4, iter: 688/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 689/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 4, iter: 690/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 691/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 4, iter: 692/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 693/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 694/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 695/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 696/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 697/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 698/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 699/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 4, iter: 700/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 701/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 702/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 4, iter: 703/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 4, iter: 704/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 705/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 706/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 707/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 708/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 709/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 710/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 711/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 712/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 713/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 4, iter: 714/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 4, iter: 715/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 716/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 4, iter: 717/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 718/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 4, iter: 719/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 720/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 4, iter: 721/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 722/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 723/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 724/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 725/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 726/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 4, iter: 727/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 728/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 729/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 730/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 731/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 4, iter: 732/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 733/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 734/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 735/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 4, iter: 736/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 737/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 4, iter: 738/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 739/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 4, iter: 740/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 4, iter: 741/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 4, iter: 742/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 743/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 4, iter: 744/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 745/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 4, iter: 746/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 4, iter: 747/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 748/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 4, iter: 749/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 750/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 4, iter: 751/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 4, iter: 752/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 4, iter: 753/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 4, iter: 754/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 755/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 4, iter: 756/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 757/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 4, iter: 758/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 4, iter: 759/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 760/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 4, iter: 761/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 762/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 763/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 764/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 4, iter: 765/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 4, iter: 766/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 767/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 4, iter: 768/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 4, iter: 769/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 4, iter: 770/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 771/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 4, iter: 772/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 4, iter: 773/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 774/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 4, iter: 775/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 776/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 4, iter: 777/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 4, iter: 778/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 4, iter: 779/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 4, iter: 780/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 4, iter: 781/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 0/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 5, iter: 1/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 2/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 5, iter: 3/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 4/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 5/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 6/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Clipped gradient with value 7.8 while allowed 6.4\n",
      "Epoch: 5, iter: 7/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 5, iter: 8/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 5, iter: 9/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 5, iter: 10/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 11/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 5, iter: 12/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 13/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 14/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 5, iter: 15/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 5, iter: 16/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 17/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 5, iter: 18/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 19/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 5, iter: 20/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 21/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 22/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 23/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 24/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 25/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 26/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 27/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 28/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 29/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 5, iter: 30/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 31/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 32/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 33/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 5, iter: 34/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 35/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 5, iter: 36/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 37/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 38/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 39/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 5, iter: 40/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 5, iter: 41/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 42/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 43/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 44/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 45/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 46/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 47/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 48/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 49/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 5, iter: 50/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 51/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 52/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 53/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 54/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 55/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 56/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 57/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 5, iter: 58/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 59/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 60/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 5, iter: 61/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 5, iter: 62/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 63/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 64/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 65/782, Loss 2.73, NLL: 2.73, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 66/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 67/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 68/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 5, iter: 69/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 70/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 5, iter: 71/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 72/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 73/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 74/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 5, iter: 75/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 76/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 77/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 78/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 79/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 80/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 81/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 82/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 83/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 84/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 85/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 86/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 5, iter: 87/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 88/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 89/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 90/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 91/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 92/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 93/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 94/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 95/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 96/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 97/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 98/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 99/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 100/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 101/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 102/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 103/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 104/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 105/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 106/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 107/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 108/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 109/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 110/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 111/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 5, iter: 112/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 113/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 114/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 115/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 116/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 5, iter: 117/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 118/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 119/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 120/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 121/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 122/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 123/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 124/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 125/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 126/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 127/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 4.9 while allowed 4.9\n",
      "Epoch: 5, iter: 128/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.9\n",
      "Clipped gradient with value 5.5 while allowed 5.1\n",
      "Epoch: 5, iter: 129/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.5\n",
      "Clipped gradient with value 10.1 while allowed 5.4\n",
      "Epoch: 5, iter: 130/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 10.1\n",
      "Clipped gradient with value 9.5 while allowed 5.7\n",
      "Epoch: 5, iter: 131/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 9.5\n",
      "Epoch: 5, iter: 132/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 8.0 while allowed 6.0\n",
      "Epoch: 5, iter: 133/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 8.0\n",
      "Clipped gradient with value 6.7 while allowed 6.3\n",
      "Epoch: 5, iter: 134/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.7\n",
      "Clipped gradient with value 6.8 while allowed 6.6\n",
      "Epoch: 5, iter: 135/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 5, iter: 136/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 5, iter: 137/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 5, iter: 138/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 5, iter: 139/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 5, iter: 140/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 5, iter: 141/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 5, iter: 142/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 143/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 5, iter: 144/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 145/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 146/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 5, iter: 147/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 148/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 149/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 150/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 151/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 152/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 153/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 154/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 155/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 156/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 157/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 158/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 5, iter: 159/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 160/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 5, iter: 161/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 162/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 163/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 164/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 5, iter: 165/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 166/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 167/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 168/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 169/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 170/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 5, iter: 171/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 172/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 5, iter: 173/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 174/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 5, iter: 175/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 176/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 177/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 178/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 5, iter: 179/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 180/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 5, iter: 181/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 182/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 5, iter: 183/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 184/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 5, iter: 185/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 9.3 while allowed 8.6\n",
      "Epoch: 5, iter: 186/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 9.3\n",
      "Epoch: 5, iter: 187/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 188/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 5, iter: 189/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 5, iter: 190/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 5, iter: 191/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 5, iter: 192/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 193/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 5, iter: 194/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 195/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 5, iter: 196/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 197/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 198/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 199/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 200/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 201/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 202/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 203/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 5, iter: 204/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 205/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 5, iter: 206/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 207/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 208/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 209/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 210/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 211/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 212/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 213/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 214/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 215/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 216/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 5, iter: 217/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 218/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 219/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 5, iter: 220/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 221/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 5, iter: 222/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 223/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 224/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 225/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 226/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 227/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 228/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 229/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 230/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 231/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 5, iter: 232/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 233/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 234/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 235/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 236/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 237/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 238/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 239/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 240/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 241/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 242/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 243/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 244/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 245/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 246/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Clipped gradient with value 4.8 while allowed 4.7\n",
      "Epoch: 5, iter: 247/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 5, iter: 248/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 5, iter: 249/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 250/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 251/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 5, iter: 252/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 8.2 while allowed 5.8\n",
      "Epoch: 5, iter: 253/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 5, iter: 254/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.3\n",
      "Clipped gradient with value 6.2 while allowed 6.1\n",
      "Epoch: 5, iter: 255/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 5, iter: 256/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 257/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 5, iter: 258/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 259/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 5, iter: 260/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.3\n",
      "Clipped gradient with value 10.1 while allowed 6.8\n",
      "Epoch: 5, iter: 261/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 10.1\n",
      "Epoch: 5, iter: 262/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 263/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 264/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 265/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 266/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 267/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 268/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 269/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 270/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 5, iter: 271/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 272/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 273/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 274/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 275/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 5, iter: 276/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 277/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 5, iter: 278/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 279/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 280/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 281/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 5, iter: 282/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 283/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 5, iter: 284/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 285/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 286/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 5, iter: 287/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 288/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 5, iter: 289/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 5, iter: 290/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 291/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 5, iter: 292/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 293/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 5, iter: 294/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 295/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 5, iter: 296/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 297/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 298/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 299/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 300/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 5, iter: 301/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 302/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 303/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 304/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 305/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 306/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 307/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 5, iter: 308/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 309/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 310/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 311/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 312/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 313/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 314/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 5, iter: 315/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 316/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 317/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 318/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 319/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 320/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 321/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 5, iter: 322/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 323/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 5, iter: 324/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 7.2 while allowed 7.2\n",
      "Epoch: 5, iter: 325/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 5, iter: 326/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 327/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 5, iter: 328/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 5, iter: 329/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 5, iter: 330/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 5, iter: 331/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 332/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 5, iter: 333/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 334/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 5, iter: 335/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 336/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 337/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 5, iter: 338/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 339/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 340/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 5, iter: 341/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 342/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 5, iter: 343/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 344/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 345/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 346/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 347/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 348/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 349/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 350/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 351/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 352/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 353/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 354/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 355/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 356/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 357/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 358/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 359/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 360/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 361/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 362/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 363/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 364/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 365/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 366/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 367/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 368/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 369/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 370/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 371/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 372/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 373/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 374/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 375/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 376/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 377/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 378/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 379/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 380/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 381/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 382/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 383/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 384/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 385/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 386/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 387/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 388/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 389/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 390/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 391/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 392/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 393/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 394/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 395/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 396/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 397/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 398/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 399/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 400/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Clipped gradient with value 5.4 while allowed 4.1\n",
      "Epoch: 5, iter: 401/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 5, iter: 402/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 403/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.5\n",
      "Clipped gradient with value 6.2 while allowed 4.6\n",
      "Epoch: 5, iter: 404/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 5, iter: 405/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Clipped gradient with value 6.5 while allowed 4.8\n",
      "Epoch: 5, iter: 406/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 5, iter: 407/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 408/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 5, iter: 409/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 410/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.0\n",
      "Clipped gradient with value 6.4 while allowed 5.3\n",
      "Epoch: 5, iter: 411/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 5, iter: 412/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.9\n",
      "Clipped gradient with value 7.8 while allowed 5.6\n",
      "Epoch: 5, iter: 413/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 5, iter: 414/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 415/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 5, iter: 416/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Clipped gradient with value 7.3 while allowed 6.2\n",
      "Epoch: 5, iter: 417/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 5, iter: 418/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.4\n",
      "Clipped gradient with value 9.8 while allowed 6.5\n",
      "Epoch: 5, iter: 419/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 9.8\n",
      "Epoch: 5, iter: 420/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 421/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 422/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 423/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 5, iter: 424/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 425/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 426/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 427/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 428/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 429/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 430/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 431/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 432/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 433/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 434/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 435/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 436/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 5, iter: 437/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 438/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 439/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 440/782, Loss 2.38, NLL: 2.38, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 441/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 442/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 443/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 5, iter: 444/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.6\n",
      "Clipped gradient with value 8.5 while allowed 7.2\n",
      "Epoch: 5, iter: 445/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 8.5\n",
      "Epoch: 5, iter: 446/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 447/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 5, iter: 448/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Clipped gradient with value 8.9 while allowed 7.9\n",
      "Epoch: 5, iter: 449/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 8.9\n",
      "Epoch: 5, iter: 450/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 451/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 5, iter: 452/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 453/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 5, iter: 454/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 5, iter: 455/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 5, iter: 456/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 457/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 458/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 5, iter: 459/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 460/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 5, iter: 461/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 462/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 463/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 464/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 465/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 466/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 5, iter: 467/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 468/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 469/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 470/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 471/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 472/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 473/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 474/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 475/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 476/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 477/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 478/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 479/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 480/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 481/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 482/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 483/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 484/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 485/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 486/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 487/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 488/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 489/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 490/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 491/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 492/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 493/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 494/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 495/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 496/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 497/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 498/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 499/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 500/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 501/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 502/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 503/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 504/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 505/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 506/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 507/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 508/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 509/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 510/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 511/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 512/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 513/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 514/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 515/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 516/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 517/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 518/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 519/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 520/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 521/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 522/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 523/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 524/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 525/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 526/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 527/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 528/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 529/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 530/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 531/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 532/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 533/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 534/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.3\n",
      "Clipped gradient with value 4.6 while allowed 4.3\n",
      "Epoch: 5, iter: 535/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 5, iter: 536/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 537/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 538/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 539/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 540/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 541/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 5, iter: 542/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.0\n",
      "Clipped gradient with value 7.1 while allowed 4.8\n",
      "Epoch: 5, iter: 543/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 5, iter: 544/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 545/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 546/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 547/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 548/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 549/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 550/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 551/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 5, iter: 552/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 553/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 554/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 555/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 556/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 557/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 558/782, Loss 2.36, NLL: 2.36, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 559/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 560/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 561/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 562/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 563/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 564/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 5, iter: 565/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 566/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 567/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 568/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 569/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 570/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 571/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 572/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 5, iter: 573/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.9\n",
      "Clipped gradient with value 6.6 while allowed 5.7\n",
      "Epoch: 5, iter: 574/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 5, iter: 575/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 576/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 5, iter: 577/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 578/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 5, iter: 579/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 5, iter: 580/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 581/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 5, iter: 582/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 5, iter: 583/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 5, iter: 584/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 5, iter: 585/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 5, iter: 586/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 587/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 5, iter: 588/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 589/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 5, iter: 590/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 591/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 592/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 593/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 594/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 595/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 596/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 597/782, Loss 2.38, NLL: 2.38, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 598/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 599/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 600/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 5, iter: 601/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 602/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 603/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 5, iter: 604/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 605/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 606/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 607/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 608/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 609/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 610/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 611/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 612/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 613/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 614/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 615/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 616/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 617/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 618/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 619/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 620/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 621/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 622/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 623/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 624/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 5, iter: 625/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 626/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 627/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 628/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 629/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 630/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 631/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 632/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 633/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 5, iter: 634/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 635/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 5, iter: 636/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 5, iter: 637/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 5, iter: 638/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 5.3\n",
      "Clipped gradient with value 6.7 while allowed 5.9\n",
      "Epoch: 5, iter: 639/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.7\n",
      "Clipped gradient with value 6.3 while allowed 6.0\n",
      "Epoch: 5, iter: 640/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.3\n",
      "Clipped gradient with value 8.8 while allowed 6.3\n",
      "Epoch: 5, iter: 641/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 8.8\n",
      "Epoch: 5, iter: 642/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 5, iter: 643/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 5, iter: 644/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 5, iter: 645/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 646/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 647/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 648/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 5, iter: 649/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 5, iter: 650/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 5, iter: 651/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 652/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 653/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 5, iter: 654/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 5, iter: 655/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.3\n",
      "Epoch: 5, iter: 656/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 657/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 5, iter: 658/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 659/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.7\n",
      "Epoch: 5, iter: 660/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 661/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 5, iter: 662/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 663/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 5, iter: 664/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 5, iter: 665/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 5, iter: 666/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 667/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 668/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 669/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 670/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 671/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 672/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 673/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 5, iter: 674/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 675/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 676/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 677/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 678/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 679/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 680/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 681/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 682/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 683/782, Loss 2.72, NLL: 2.72, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 684/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 685/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 686/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 5, iter: 687/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 688/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 689/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 690/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 691/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 692/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 693/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 694/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 5, iter: 695/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 696/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 697/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 698/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 699/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 700/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 5, iter: 701/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 702/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 703/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 5, iter: 704/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 705/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 5, iter: 706/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.6\n",
      "Clipped gradient with value 7.8 while allowed 7.6\n",
      "Epoch: 5, iter: 707/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 5, iter: 708/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 5, iter: 709/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 5, iter: 710/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 711/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 5, iter: 712/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 713/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 5, iter: 714/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 715/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 5, iter: 716/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.7\n",
      "Clipped gradient with value 8.3 while allowed 7.7\n",
      "Epoch: 5, iter: 717/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 8.3\n",
      "Epoch: 5, iter: 718/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 719/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 5, iter: 720/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 721/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 722/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 723/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 5, iter: 724/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 725/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 726/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 5, iter: 727/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 5, iter: 728/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 5, iter: 729/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 5, iter: 730/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 5, iter: 731/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 5, iter: 732/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 5, iter: 733/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 5, iter: 734/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 735/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 5, iter: 736/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 5, iter: 737/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 738/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 5, iter: 739/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 740/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 741/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 5, iter: 742/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 5, iter: 743/782, Loss 2.75, NLL: 2.75, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 744/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 745/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 746/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 5, iter: 747/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 5, iter: 748/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 749/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 750/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 751/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 5, iter: 752/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 753/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 754/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 755/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 5, iter: 756/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 757/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 5, iter: 758/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.9\n",
      "Epoch: 5, iter: 759/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 5, iter: 760/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 5, iter: 761/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 5, iter: 762/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 5, iter: 763/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 5, iter: 764/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 5, iter: 765/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 5, iter: 766/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 5, iter: 767/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 5, iter: 768/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 5, iter: 769/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 5, iter: 770/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 5, iter: 771/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 5, iter: 772/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 5, iter: 773/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 5, iter: 774/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 5, iter: 775/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 5, iter: 776/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 5, iter: 777/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 5, iter: 778/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 5, iter: 779/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 5, iter: 780/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 5, iter: 781/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 6, iter: 0/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 1/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 2/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 3/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 4/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 5/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 6, iter: 6/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 7/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 8/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 9/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 10/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 11/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 12/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 13/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 14/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 15/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 6, iter: 16/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 17/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 18/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 19/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 20/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 6, iter: 21/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 22/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 23/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 24/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 6, iter: 25/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 26/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 6, iter: 27/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 28/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 6, iter: 29/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 6, iter: 30/782, Loss 2.39, NLL: 2.39, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 6, iter: 31/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 32/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 33/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Clipped gradient with value 7.5 while allowed 7.1\n",
      "Epoch: 6, iter: 34/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 6, iter: 35/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 36/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 37/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 38/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 6, iter: 39/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 6, iter: 40/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 41/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 42/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 43/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 44/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 45/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 46/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 47/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 48/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 49/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 50/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 51/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 52/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 53/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 54/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 55/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 56/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 57/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 58/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 59/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 60/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 61/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 62/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 63/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 64/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 65/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 66/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 67/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 68/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 69/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 70/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 71/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 72/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 73/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 6, iter: 74/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 75/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 76/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 77/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 6, iter: 78/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 79/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 80/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 81/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 82/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 83/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 84/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 85/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.4\n",
      "Clipped gradient with value 5.1 while allowed 5.0\n",
      "Epoch: 6, iter: 86/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 6, iter: 87/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 88/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 6, iter: 89/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 6, iter: 90/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 91/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 92/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 93/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 94/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 95/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 96/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 6, iter: 97/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.7\n",
      "Clipped gradient with value 6.8 while allowed 5.8\n",
      "Epoch: 6, iter: 98/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 6.8\n",
      "Epoch: 6, iter: 99/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Clipped gradient with value 8.0 while allowed 6.0\n",
      "Epoch: 6, iter: 100/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 8.0\n",
      "Epoch: 6, iter: 101/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 102/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 6, iter: 103/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.9\n",
      "Clipped gradient with value 6.6 while allowed 6.4\n",
      "Epoch: 6, iter: 104/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 6, iter: 105/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.6\n",
      "Clipped gradient with value 7.8 while allowed 6.9\n",
      "Epoch: 6, iter: 106/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 7.8\n",
      "Epoch: 6, iter: 107/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 108/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 109/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 6, iter: 110/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 111/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 6, iter: 112/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 113/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 6, iter: 114/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 115/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 116/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 117/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 118/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 6, iter: 119/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 120/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 121/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 122/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 123/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 124/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 125/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 126/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 127/782, Loss 2.74, NLL: 2.74, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 128/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 129/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 130/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 131/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 132/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 133/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 134/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 135/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 136/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 137/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 138/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 139/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 140/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 141/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 142/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 6, iter: 143/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 144/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 6, iter: 145/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 146/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 147/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 148/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 6, iter: 149/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 150/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 6, iter: 151/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 152/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 153/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 154/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 6, iter: 155/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 6, iter: 156/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 6, iter: 157/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 158/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 6, iter: 159/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 160/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 161/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 162/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 6, iter: 163/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 164/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 165/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 166/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 167/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 168/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 169/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 170/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 171/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 172/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 173/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 174/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 175/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 176/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 177/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 178/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 179/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 6, iter: 180/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 181/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 6, iter: 182/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 183/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 6, iter: 184/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 185/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 186/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 187/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 188/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 6, iter: 189/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 190/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 6, iter: 191/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 192/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 193/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 194/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 195/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 196/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 6, iter: 197/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 6, iter: 198/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.9\n",
      "Clipped gradient with value 7.1 while allowed 7.1\n",
      "Epoch: 6, iter: 199/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 7.1\n",
      "Epoch: 6, iter: 200/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 201/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 6, iter: 202/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 203/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 204/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 6, iter: 205/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 206/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 6, iter: 207/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 208/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 209/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 210/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 6, iter: 211/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 212/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 213/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 6, iter: 214/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 215/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 216/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 217/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 218/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 219/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 220/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 221/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 222/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 223/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 6, iter: 224/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 225/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 6, iter: 226/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 6, iter: 227/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 6, iter: 228/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 229/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 6, iter: 230/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 231/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 6, iter: 232/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 233/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 234/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 235/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 6, iter: 236/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 237/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 238/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 239/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 240/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 241/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 242/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 243/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 6, iter: 244/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 245/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 246/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 247/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 248/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 249/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 250/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 251/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 252/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 253/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 254/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 255/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 256/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 257/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 258/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 259/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 260/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 261/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 262/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 263/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 264/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 265/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 266/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 267/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 268/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 269/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 270/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 271/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 6, iter: 272/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 273/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 274/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 275/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 6, iter: 276/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 277/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 278/782, Loss 2.38, NLL: 2.38, RegTerm: 0.0, GradNorm: 3.3\n",
      "Clipped gradient with value 6.2 while allowed 5.2\n",
      "Epoch: 6, iter: 279/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 6, iter: 280/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.8\n",
      "Clipped gradient with value 6.6 while allowed 5.6\n",
      "Epoch: 6, iter: 281/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 6, iter: 282/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 283/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 284/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 285/782, Loss 2.39, NLL: 2.39, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 286/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 287/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 288/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 289/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 290/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Clipped gradient with value 7.2 while allowed 5.8\n",
      "Epoch: 6, iter: 291/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 6, iter: 292/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 6, iter: 293/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 294/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 295/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 6, iter: 296/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 297/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 6, iter: 298/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 299/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 6, iter: 300/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 4.7\n",
      "Clipped gradient with value 7.9 while allowed 6.8\n",
      "Epoch: 6, iter: 301/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 7.9\n",
      "Clipped gradient with value 10.1 while allowed 7.2\n",
      "Epoch: 6, iter: 302/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 10.1\n",
      "Epoch: 6, iter: 303/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 6, iter: 304/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 305/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 306/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 307/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 308/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 6, iter: 309/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 310/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 311/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 312/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 313/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 314/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 315/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 316/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 317/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 6, iter: 318/782, Loss 2.35, NLL: 2.35, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 319/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 320/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 321/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 6, iter: 322/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 323/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 324/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 325/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 326/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 327/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 328/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 329/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 330/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 331/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 332/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 333/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 334/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 6, iter: 335/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 336/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 337/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 338/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 6.4\n",
      "Epoch: 6, iter: 339/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 340/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 341/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 342/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 343/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 344/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 345/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 346/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 347/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 348/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 349/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 6, iter: 350/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 351/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 352/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 353/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 354/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 355/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 356/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 357/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 358/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 359/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 360/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 361/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 362/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 363/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 364/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 365/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 366/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 367/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 368/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 369/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 370/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 6, iter: 371/782, Loss 2.38, NLL: 2.38, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 372/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 373/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 374/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 375/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 376/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 377/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 378/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 379/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 380/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 381/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 382/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 383/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 384/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.9\n",
      "Clipped gradient with value 5.8 while allowed 5.2\n",
      "Epoch: 6, iter: 385/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 6, iter: 386/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 387/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 6, iter: 388/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 389/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 390/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 391/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 392/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 393/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 0.8\n",
      "Clipped gradient with value 6.5 while allowed 4.9\n",
      "Epoch: 6, iter: 394/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 6, iter: 395/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 396/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 397/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 398/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 399/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 400/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 401/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 402/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 403/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 404/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 405/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 406/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 407/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 408/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Clipped gradient with value 5.1 while allowed 4.9\n",
      "Epoch: 6, iter: 409/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 6, iter: 410/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 6, iter: 411/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 412/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 413/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 414/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 415/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 416/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 6, iter: 417/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 418/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 419/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 420/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 421/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 422/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 423/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 424/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 425/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 426/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 427/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 428/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 429/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 6, iter: 430/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 431/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 432/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 433/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 434/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 435/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 436/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 437/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 6, iter: 438/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 439/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 6, iter: 440/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 441/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 6, iter: 442/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 443/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 444/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 445/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 446/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 6, iter: 447/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 448/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 6, iter: 449/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 450/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 6, iter: 451/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 452/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 453/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 454/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 455/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 6, iter: 456/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 457/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 458/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 459/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 460/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 461/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 462/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 463/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 464/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 465/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 466/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 467/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 468/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 469/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 470/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 471/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 6, iter: 472/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 473/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 474/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 475/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 476/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 477/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 478/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 479/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 6, iter: 480/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 481/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 482/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 483/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 484/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 485/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 486/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 6, iter: 487/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 488/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 6, iter: 489/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 490/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 6, iter: 491/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 492/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 493/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 494/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 495/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 496/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 6, iter: 497/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 498/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 499/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 500/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 501/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 502/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 503/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 504/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 6, iter: 505/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 506/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 507/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 508/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 509/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 510/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 511/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 512/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 513/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 514/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 515/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 516/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 517/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 518/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 519/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 520/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 521/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 522/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 523/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 524/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 525/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 526/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 527/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 528/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 529/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 530/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 531/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 532/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 533/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 6, iter: 534/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 535/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 536/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 6, iter: 537/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 538/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 539/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 540/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 541/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 6, iter: 542/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 543/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 544/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 545/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 546/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 547/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 548/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 549/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 550/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 551/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 552/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 553/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 554/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 555/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 556/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 557/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 558/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 559/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 560/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 6, iter: 561/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 6, iter: 562/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 563/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 564/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 565/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 566/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 567/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 568/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 569/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Clipped gradient with value 5.3 while allowed 5.2\n",
      "Epoch: 6, iter: 570/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 6, iter: 571/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 572/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 6, iter: 573/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 574/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 6, iter: 575/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 576/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 6, iter: 577/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 578/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 579/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 580/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 581/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 582/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 583/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 584/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 585/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 586/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 587/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 588/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 589/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 590/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 591/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 592/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 593/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 6, iter: 594/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 595/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 596/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 597/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 598/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 599/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 600/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 601/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 602/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 603/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 6, iter: 604/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 605/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 606/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 6, iter: 607/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 6, iter: 608/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 609/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 610/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 7.2 while allowed 6.0\n",
      "Epoch: 6, iter: 611/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 7.2\n",
      "Epoch: 6, iter: 612/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Clipped gradient with value 7.0 while allowed 6.3\n",
      "Epoch: 6, iter: 613/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 6, iter: 614/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.7\n",
      "Clipped gradient with value 6.7 while allowed 6.6\n",
      "Epoch: 6, iter: 615/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 6.7\n",
      "Epoch: 6, iter: 616/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 617/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 618/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 619/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 620/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 621/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 622/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 623/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 6, iter: 624/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 6, iter: 625/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 6, iter: 626/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 627/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 6, iter: 628/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 629/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 630/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 631/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 632/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 633/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 634/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 6, iter: 635/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 636/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 637/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 638/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 639/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 640/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 641/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 6, iter: 642/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 643/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 6, iter: 644/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 645/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 646/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 6, iter: 647/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 6, iter: 648/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 6, iter: 649/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 6, iter: 650/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 651/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 652/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 653/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 654/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 655/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 656/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 657/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 658/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 659/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 660/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 661/782, Loss 2.39, NLL: 2.39, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 662/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 663/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 6, iter: 664/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 665/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 666/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 667/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 6, iter: 668/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 669/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 670/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 671/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 672/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 673/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 674/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 675/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 676/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 677/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 678/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 679/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 680/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 681/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 682/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 683/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 684/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 6, iter: 685/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 686/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 687/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 688/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 689/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 690/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 6, iter: 691/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 692/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 693/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 694/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 695/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 696/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 697/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 698/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 699/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 700/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 701/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 702/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 703/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 704/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 705/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 706/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 707/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 6, iter: 708/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 709/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 710/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 711/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 6, iter: 712/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 713/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 714/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 715/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 6, iter: 716/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 6, iter: 717/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 718/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 719/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 720/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 721/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 722/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 723/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 724/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 6, iter: 725/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 6, iter: 726/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 4.4 while allowed 4.0\n",
      "Epoch: 6, iter: 727/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 6, iter: 728/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 729/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 730/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 731/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 732/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 733/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 734/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 6, iter: 735/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 736/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.3\n",
      "Clipped gradient with value 4.4 while allowed 3.7\n",
      "Epoch: 6, iter: 737/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 6, iter: 738/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 739/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 740/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 741/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 742/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Clipped gradient with value 6.2 while allowed 4.0\n",
      "Epoch: 6, iter: 743/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 6, iter: 744/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 745/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 746/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 6, iter: 747/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 748/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 749/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Clipped gradient with value 4.4 while allowed 4.4\n",
      "Epoch: 6, iter: 750/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 6, iter: 751/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 6, iter: 752/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 753/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 6, iter: 754/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 6, iter: 755/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 756/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 6, iter: 757/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 758/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 759/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 6, iter: 760/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 6, iter: 761/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 6, iter: 762/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 763/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 6, iter: 764/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 765/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 766/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 6, iter: 767/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 6, iter: 768/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 6, iter: 769/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 6, iter: 770/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 6, iter: 771/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 6, iter: 772/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 773/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 774/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 6, iter: 775/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 6, iter: 776/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 6, iter: 777/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 6, iter: 778/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 6, iter: 779/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 6, iter: 780/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 6, iter: 781/782, Loss 2.35, NLL: 2.35, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 0/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 7, iter: 1/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 2/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 3/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 4/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 5/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 6/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 7/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 8/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 9/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 10/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 11/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 12/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 13/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 14/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 7, iter: 15/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 16/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 17/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 7, iter: 18/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 19/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 20/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 21/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 22/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 23/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 24/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 25/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 26/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 27/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 28/782, Loss 2.77, NLL: 2.77, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 29/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 30/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 31/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 32/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 33/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 34/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 7, iter: 35/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 36/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 37/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 38/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 39/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 40/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Clipped gradient with value 5.8 while allowed 5.4\n",
      "Epoch: 7, iter: 41/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.8\n",
      "Clipped gradient with value 7.6 while allowed 5.7\n",
      "Epoch: 7, iter: 42/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 7.6\n",
      "Epoch: 7, iter: 43/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 44/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 7, iter: 45/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 46/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 7, iter: 47/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 48/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 49/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 50/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 51/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 7, iter: 52/782, Loss 2.39, NLL: 2.39, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 53/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 54/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 55/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 56/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 57/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 58/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 59/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 60/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 61/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 62/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 63/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 64/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 65/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 66/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 67/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 7, iter: 68/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 69/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 70/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 71/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 72/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 73/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 74/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 75/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 76/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 77/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 78/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 79/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 80/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 7, iter: 81/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 82/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 83/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 84/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Clipped gradient with value 6.1 while allowed 6.0\n",
      "Epoch: 7, iter: 85/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 6.1\n",
      "Epoch: 7, iter: 86/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 87/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 88/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 89/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 90/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 91/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 92/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 93/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 94/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 95/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 96/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 7, iter: 97/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 0.9\n",
      "Clipped gradient with value 5.7 while allowed 5.5\n",
      "Epoch: 7, iter: 98/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 7, iter: 99/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 100/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 101/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 102/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 103/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 104/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 105/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 106/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 107/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 108/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 109/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 110/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 111/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 112/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 113/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 114/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 115/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 116/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 117/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 118/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 119/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 120/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 121/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 122/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 123/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 124/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 125/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 126/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 127/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 128/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 129/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 130/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 131/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 132/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 133/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 134/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 135/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 136/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 137/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 138/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 139/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 140/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 141/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 142/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 143/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 7, iter: 144/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 145/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 146/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 147/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 148/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 149/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 150/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 151/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 152/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 153/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 154/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 155/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 156/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 157/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 158/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 159/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 160/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 161/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 162/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 163/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 164/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 165/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 166/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 167/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 168/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 169/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 170/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 171/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 172/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 173/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 174/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 175/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 176/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 177/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 178/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 179/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 180/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.2\n",
      "Clipped gradient with value 4.8 while allowed 4.3\n",
      "Epoch: 7, iter: 181/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 7, iter: 182/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 183/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 184/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 185/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 186/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 187/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 188/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 189/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 190/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 191/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 192/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 7, iter: 193/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 194/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 195/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 196/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 197/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 198/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Clipped gradient with value 4.9 while allowed 4.9\n",
      "Epoch: 7, iter: 199/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 7, iter: 200/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 201/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 202/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 203/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 204/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 205/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 206/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 207/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 208/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 209/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 210/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 211/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 212/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 213/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 214/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 215/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 216/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 217/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 218/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 219/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 220/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 221/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 222/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 223/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 224/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 225/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 226/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 227/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 228/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 7, iter: 229/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 230/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 231/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 232/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 233/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 234/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 235/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 236/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 237/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 238/782, Loss 2.75, NLL: 2.75, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 7, iter: 239/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 240/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 241/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 242/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 7, iter: 243/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 244/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 7, iter: 245/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 246/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 247/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 248/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 7, iter: 249/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 250/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 7, iter: 251/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 252/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 7, iter: 253/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.6\n",
      "Clipped gradient with value 8.1 while allowed 6.9\n",
      "Epoch: 7, iter: 254/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 8.1\n",
      "Clipped gradient with value 7.4 while allowed 7.3\n",
      "Epoch: 7, iter: 255/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 7.4\n",
      "Clipped gradient with value 9.2 while allowed 7.7\n",
      "Epoch: 7, iter: 256/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 9.2\n",
      "Clipped gradient with value 13.2 while allowed 8.1\n",
      "Epoch: 7, iter: 257/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 13.2\n",
      "Epoch: 7, iter: 258/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.9\n",
      "Clipped gradient with value 8.8 while allowed 8.5\n",
      "Epoch: 7, iter: 259/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 8.8\n",
      "Epoch: 7, iter: 260/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 261/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 7, iter: 262/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 263/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 264/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 265/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 266/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 267/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 268/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 269/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 270/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 271/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 272/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 273/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 274/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 7, iter: 275/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 276/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 277/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.3\n",
      "Epoch: 7, iter: 278/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 279/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 280/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 281/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 282/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 7, iter: 283/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 284/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 285/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 286/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 287/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 288/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 289/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 290/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 291/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 292/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 293/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 294/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 295/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 296/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 297/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 298/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 299/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 300/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 301/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 302/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 303/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 304/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 305/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 306/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 307/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 308/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 309/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 310/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 311/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 312/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 7, iter: 313/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 314/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 315/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 316/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 317/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 7, iter: 318/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 7, iter: 319/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 320/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 321/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 322/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 7, iter: 323/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 324/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 325/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 7, iter: 326/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 327/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 328/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 329/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 330/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 331/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 332/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 333/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 334/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 335/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 336/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 7, iter: 337/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 338/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 339/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 7, iter: 340/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 341/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 342/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 343/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 344/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 345/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 346/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 347/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 348/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 349/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 350/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 351/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 352/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.0\n",
      "Clipped gradient with value 7.0 while allowed 5.9\n",
      "Epoch: 7, iter: 353/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 7.0\n",
      "Epoch: 7, iter: 354/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.8\n",
      "Clipped gradient with value 7.4 while allowed 6.2\n",
      "Epoch: 7, iter: 355/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 7, iter: 356/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 7, iter: 357/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 7, iter: 358/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 359/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 360/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 361/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 362/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 363/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 364/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 7, iter: 365/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 7, iter: 366/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 7, iter: 367/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 368/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 369/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 370/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 371/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 372/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 373/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 374/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 375/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 376/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 377/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 378/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 379/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 380/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 381/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 382/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 383/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 384/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 7, iter: 385/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 386/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 387/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.9\n",
      "Epoch: 7, iter: 388/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 389/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 390/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 391/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 7, iter: 392/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 393/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 7, iter: 394/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 395/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 396/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 397/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 398/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 399/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 400/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 401/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 402/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 403/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 404/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 405/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 406/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 407/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 7, iter: 408/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 409/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 410/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 411/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 412/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 413/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 7, iter: 414/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 415/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 416/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 417/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 418/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 419/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 420/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 421/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 422/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 423/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 424/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 425/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 426/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 7, iter: 427/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 428/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 429/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 430/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 431/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 432/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 433/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 434/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 435/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 436/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 437/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Clipped gradient with value 5.8 while allowed 5.3\n",
      "Epoch: 7, iter: 438/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.8\n",
      "Epoch: 7, iter: 439/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 7, iter: 440/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 441/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 442/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 443/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 444/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 445/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 446/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 447/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 448/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 449/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 450/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 451/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 452/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 453/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 454/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 455/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 456/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 457/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 458/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 459/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 460/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 461/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 462/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 463/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 7, iter: 464/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 465/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 7, iter: 466/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 467/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 7, iter: 468/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 469/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 470/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 471/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 472/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 473/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 474/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 475/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 476/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 477/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 478/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 479/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 480/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 7, iter: 481/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 482/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 483/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 484/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 485/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 486/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 487/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 488/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 489/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 7, iter: 490/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 491/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 492/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 493/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 494/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 495/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 496/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 497/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 498/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 499/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 500/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 501/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 502/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 503/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 504/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 505/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 506/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 507/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 508/782, Loss 2.78, NLL: 2.78, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 509/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 510/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 511/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 512/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 513/782, Loss 2.67, NLL: 2.67, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 514/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 515/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 516/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 517/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 518/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 519/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 520/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 521/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 522/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 523/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 524/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 525/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 526/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 527/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 528/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 529/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 530/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 531/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 532/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 533/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 534/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 535/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 536/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 537/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 538/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 539/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 7, iter: 540/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Clipped gradient with value 4.6 while allowed 4.6\n",
      "Epoch: 7, iter: 541/782, Loss 2.38, NLL: 2.38, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 542/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Clipped gradient with value 5.1 while allowed 4.8\n",
      "Epoch: 7, iter: 543/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 7, iter: 544/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.7\n",
      "Clipped gradient with value 6.6 while allowed 5.0\n",
      "Epoch: 7, iter: 545/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 6.6\n",
      "Epoch: 7, iter: 546/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 547/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 548/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 549/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 550/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 551/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 7, iter: 552/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.7\n",
      "Clipped gradient with value 6.5 while allowed 5.6\n",
      "Epoch: 7, iter: 553/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 6.5\n",
      "Epoch: 7, iter: 554/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 555/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.1\n",
      "Clipped gradient with value 6.2 while allowed 6.1\n",
      "Epoch: 7, iter: 556/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 7, iter: 557/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 5.8\n",
      "Clipped gradient with value 7.4 while allowed 6.7\n",
      "Epoch: 7, iter: 558/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 7, iter: 559/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 7, iter: 560/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 7, iter: 561/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 562/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 7, iter: 563/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 564/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.7\n",
      "Epoch: 7, iter: 565/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 7, iter: 566/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 567/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 568/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 569/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 570/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 571/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 572/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 573/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 574/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 7, iter: 575/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 576/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 577/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 578/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 579/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 580/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 581/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 582/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 583/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 584/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 585/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.2\n",
      "Epoch: 7, iter: 586/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 7, iter: 587/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 7, iter: 588/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 589/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 7, iter: 590/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 591/782, Loss 2.37, NLL: 2.37, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 7, iter: 592/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 593/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 594/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 595/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 596/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 597/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 598/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 599/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 7, iter: 600/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 601/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 7, iter: 602/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 603/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 604/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 7, iter: 605/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 7, iter: 606/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 607/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 608/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 609/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 610/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 611/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 612/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 7, iter: 613/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 614/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 615/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 616/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 617/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.5\n",
      "Epoch: 7, iter: 618/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 619/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 7, iter: 620/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 621/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 622/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 623/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 624/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 625/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 626/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 627/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 7, iter: 628/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 629/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 630/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 631/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 632/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 633/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 634/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 635/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 636/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 637/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 5.5\n",
      "Epoch: 7, iter: 638/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 639/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 640/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 641/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 642/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 643/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 644/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 7, iter: 645/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 646/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 647/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 7, iter: 648/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 649/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.3\n",
      "Epoch: 7, iter: 650/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 651/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 652/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 5.6\n",
      "Epoch: 7, iter: 653/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Clipped gradient with value 8.2 while allowed 6.8\n",
      "Epoch: 7, iter: 654/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 8.2\n",
      "Epoch: 7, iter: 655/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 656/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 5.4\n",
      "Epoch: 7, iter: 657/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 5.5\n",
      "Clipped gradient with value 7.5 while allowed 7.4\n",
      "Epoch: 7, iter: 658/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 7.5\n",
      "Epoch: 7, iter: 659/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 7, iter: 660/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 7, iter: 661/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 7.4\n",
      "Epoch: 7, iter: 662/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 663/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 7, iter: 664/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 7, iter: 665/782, Loss 2.37, NLL: 2.37, RegTerm: 0.0, GradNorm: 5.3\n",
      "Epoch: 7, iter: 666/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 667/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 3.4\n",
      "Epoch: 7, iter: 668/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 5.1\n",
      "Epoch: 7, iter: 669/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 7, iter: 670/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 671/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 672/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 673/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 674/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 675/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 676/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 677/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 678/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 679/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 680/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 681/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 682/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 683/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 684/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 7, iter: 685/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 686/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 687/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 688/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 689/782, Loss 2.39, NLL: 2.39, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 690/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 691/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 692/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 0.6\n",
      "Epoch: 7, iter: 693/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 7, iter: 694/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 695/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 696/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 7, iter: 697/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 698/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 699/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 700/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 701/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 702/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 703/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 704/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 705/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 706/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 707/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 7, iter: 708/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 709/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 7, iter: 710/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 711/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 7, iter: 712/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 713/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 714/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 715/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 716/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 717/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 7, iter: 718/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 7, iter: 719/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 720/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 7, iter: 721/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 722/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 723/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 724/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 725/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 726/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 7, iter: 727/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 7, iter: 728/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 729/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 730/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 731/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 732/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 733/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 734/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 735/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 7, iter: 736/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 737/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 738/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 739/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 740/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 7, iter: 741/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 742/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 743/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 744/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 745/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 746/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 7, iter: 747/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 748/782, Loss 2.70, NLL: 2.70, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 749/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 750/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 751/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 752/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 753/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 754/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 7, iter: 755/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 7, iter: 756/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 757/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 7, iter: 758/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 759/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 7, iter: 760/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 761/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 7, iter: 762/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 763/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 7, iter: 764/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 7, iter: 765/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 766/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 7, iter: 767/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 7, iter: 768/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 7, iter: 769/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 7, iter: 770/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 7, iter: 771/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 7, iter: 772/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 7, iter: 773/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 7, iter: 774/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.0\n",
      "Clipped gradient with value 6.0 while allowed 5.2\n",
      "Epoch: 7, iter: 775/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 6.0\n",
      "Epoch: 7, iter: 776/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 7, iter: 777/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 7, iter: 778/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 7, iter: 779/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 7, iter: 780/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 4.9\n",
      "Epoch: 7, iter: 781/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 0/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 8, iter: 1/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 8, iter: 2/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 3/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 4/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 8, iter: 5/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 8, iter: 6/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 8, iter: 7/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 8/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 9/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 10/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 11/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 12/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 13/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 14/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 15/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 16/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 17/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 18/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 8, iter: 19/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 20/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 8, iter: 21/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 22/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 23/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 24/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 25/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 26/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 8, iter: 27/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 8, iter: 28/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 29/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 8, iter: 30/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 31/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 32/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 8, iter: 33/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 8, iter: 34/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 35/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 36/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 37/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 38/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 39/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 40/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 41/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 42/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 43/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 44/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 8, iter: 45/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 8, iter: 46/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 47/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 8, iter: 48/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 49/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 50/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 51/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 52/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 53/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 8, iter: 54/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.0\n",
      "Clipped gradient with value 5.0 while allowed 4.5\n",
      "Epoch: 8, iter: 55/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 5.0\n",
      "Epoch: 8, iter: 56/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 57/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 8, iter: 58/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 59/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 8, iter: 60/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 61/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 8, iter: 62/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 63/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 8, iter: 64/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 65/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Clipped gradient with value 6.2 while allowed 5.0\n",
      "Epoch: 8, iter: 66/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 6.2\n",
      "Epoch: 8, iter: 67/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 68/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 69/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 70/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 71/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 72/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 8, iter: 73/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 74/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 8, iter: 75/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 76/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 77/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 78/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 79/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 80/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 81/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 82/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 83/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 84/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 8, iter: 85/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 86/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 87/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 88/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 0.5\n",
      "Epoch: 8, iter: 89/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 90/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 91/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 92/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 93/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 94/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 8, iter: 95/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 96/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 4.4\n",
      "Epoch: 8, iter: 97/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 98/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 99/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 100/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 101/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 102/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 103/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 104/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 105/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 106/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 107/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 108/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 8, iter: 109/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 110/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 111/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 112/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 113/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 114/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 115/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 8, iter: 116/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 117/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 118/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 8, iter: 119/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 8, iter: 120/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 121/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 122/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 123/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 124/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 125/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 126/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 127/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 128/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 129/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 130/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 131/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 132/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 8, iter: 133/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 134/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 135/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 136/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 137/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 8, iter: 138/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 139/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 140/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 141/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 3.9\n",
      "Epoch: 8, iter: 142/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 143/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 8, iter: 144/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 145/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 146/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 147/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 148/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 149/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 150/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 151/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 152/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 8, iter: 153/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 154/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 155/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 4.0\n",
      "Epoch: 8, iter: 156/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 157/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 8, iter: 158/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 8, iter: 159/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 160/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.6\n",
      "Epoch: 8, iter: 161/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 8, iter: 162/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 3.5\n",
      "Epoch: 8, iter: 163/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 8, iter: 164/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 165/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 8, iter: 166/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 167/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 8, iter: 168/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 8, iter: 169/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 8, iter: 170/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 171/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 172/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 173/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.7\n",
      "Epoch: 8, iter: 174/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 175/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 176/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 177/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 178/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 8, iter: 179/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 180/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 8, iter: 181/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 182/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 183/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 184/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 185/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 186/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.8\n",
      "Clipped gradient with value 5.7 while allowed 5.4\n",
      "Epoch: 8, iter: 187/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 5.7\n",
      "Epoch: 8, iter: 188/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 189/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 8, iter: 190/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 191/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 192/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 193/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 8, iter: 194/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 195/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 196/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 197/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 198/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 199/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 200/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 201/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 202/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 203/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 204/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 205/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 206/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 0.5\n",
      "Epoch: 8, iter: 207/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 208/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 209/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 210/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 211/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 212/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 8, iter: 213/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 214/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 8, iter: 215/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 216/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 8, iter: 217/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 0.8\n",
      "Epoch: 8, iter: 218/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 8, iter: 219/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 220/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 8, iter: 221/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 4.1\n",
      "Epoch: 8, iter: 222/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 223/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 224/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 225/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 226/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 227/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 228/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 8, iter: 229/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 230/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 8, iter: 231/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 8, iter: 232/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 8, iter: 233/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 4.8\n",
      "Epoch: 8, iter: 234/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 235/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 4.2\n",
      "Epoch: 8, iter: 236/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 237/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 238/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 8, iter: 239/782, Loss 2.45, NLL: 2.45, RegTerm: 0.0, GradNorm: 3.1\n",
      "Epoch: 8, iter: 240/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 241/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.4\n",
      "Epoch: 8, iter: 242/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 243/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 3.6\n",
      "Epoch: 8, iter: 244/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 8, iter: 245/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 3.7\n",
      "Epoch: 8, iter: 246/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 247/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 248/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 0.9\n",
      "Epoch: 8, iter: 249/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 250/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 2.8\n",
      "Epoch: 8, iter: 251/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 252/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 253/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 254/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 255/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 8, iter: 256/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 257/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 258/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 259/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 260/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 261/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 262/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 263/782, Loss 2.43, NLL: 2.43, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 264/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 265/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 266/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 8, iter: 267/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.3\n",
      "Epoch: 8, iter: 268/782, Loss 2.71, NLL: 2.71, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 8, iter: 269/782, Loss 2.65, NLL: 2.65, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 270/782, Loss 2.69, NLL: 2.69, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 271/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 272/782, Loss 2.40, NLL: 2.40, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 273/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 274/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 275/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 276/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 277/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 278/782, Loss 2.56, NLL: 2.56, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 279/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 280/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 3.8\n",
      "Epoch: 8, iter: 281/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 282/782, Loss 2.66, NLL: 2.66, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 283/782, Loss 2.60, NLL: 2.60, RegTerm: 0.0, GradNorm: 2.9\n",
      "Epoch: 8, iter: 284/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 285/782, Loss 2.62, NLL: 2.62, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 286/782, Loss 2.58, NLL: 2.58, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 287/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 8, iter: 288/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 289/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 3.2\n",
      "Epoch: 8, iter: 290/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.7\n",
      "Epoch: 8, iter: 291/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 292/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 293/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.8\n",
      "Epoch: 8, iter: 294/782, Loss 2.42, NLL: 2.42, RegTerm: 0.0, GradNorm: 1.3\n",
      "Epoch: 8, iter: 295/782, Loss 2.64, NLL: 2.64, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 296/782, Loss 2.52, NLL: 2.52, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 297/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 2.6\n",
      "Epoch: 8, iter: 298/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 299/782, Loss 2.54, NLL: 2.54, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 300/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 301/782, Loss 2.48, NLL: 2.48, RegTerm: 0.0, GradNorm: 1.9\n",
      "Epoch: 8, iter: 302/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 303/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 2.3\n",
      "Epoch: 8, iter: 304/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 305/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 1.0\n",
      "Epoch: 8, iter: 306/782, Loss 2.59, NLL: 2.59, RegTerm: 0.0, GradNorm: 3.0\n",
      "Epoch: 8, iter: 307/782, Loss 2.51, NLL: 2.51, RegTerm: 0.0, GradNorm: 2.5\n",
      "Epoch: 8, iter: 308/782, Loss 2.41, NLL: 2.41, RegTerm: 0.0, GradNorm: 1.4\n",
      "Epoch: 8, iter: 309/782, Loss 2.47, NLL: 2.47, RegTerm: 0.0, GradNorm: 2.1\n",
      "Epoch: 8, iter: 310/782, Loss 2.68, NLL: 2.68, RegTerm: 0.0, GradNorm: 2.2\n",
      "Epoch: 8, iter: 311/782, Loss 2.50, NLL: 2.50, RegTerm: 0.0, GradNorm: 1.5\n",
      "Epoch: 8, iter: 312/782, Loss 2.53, NLL: 2.53, RegTerm: 0.0, GradNorm: 2.0\n",
      "Epoch: 8, iter: 313/782, Loss 2.61, NLL: 2.61, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 314/782, Loss 2.57, NLL: 2.57, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 315/782, Loss 2.46, NLL: 2.46, RegTerm: 0.0, GradNorm: 1.6\n",
      "Epoch: 8, iter: 316/782, Loss 2.49, NLL: 2.49, RegTerm: 0.0, GradNorm: 2.7\n",
      "Epoch: 8, iter: 317/782, Loss 2.55, NLL: 2.55, RegTerm: 0.0, GradNorm: 1.2\n",
      "Epoch: 8, iter: 318/782, Loss 2.63, NLL: 2.63, RegTerm: 0.0, GradNorm: 1.1\n",
      "Epoch: 8, iter: 319/782, Loss 2.44, NLL: 2.44, RegTerm: 0.0, GradNorm: 1.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from train_test import train_epoch\n",
    "for epoch in range(0, 10):\n",
    "    train_epoch(args=args, loader=dataloaders['train'], epoch=epoch, model=model, model_dp=model_dp,\n",
    "                    model_ema=model_ema, ema=ema, device=device, dtype=torch.float32, property_norms=property_norms,\n",
    "                    nodes_dist=nodes_dist, dataset_info=dataset_info,\n",
    "                    gradnorm_queue=gradnorm_queue, optim=optim, prop_dist=prop_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
